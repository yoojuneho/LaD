{
  "overall": 0.853448275862069,
  "conflict": 0.7724137931034483,
  "nonconflict": 0.9344827586206896,
  "results": [
    {
      "id": 95,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states that Ethiopia's government denies the allegations by Fano, while Doc 5 claims the United Nations denies them, creating a factual contradiction about which entity is making the denial.\"\n}"
    },
    {
      "id": 210,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"The documents contradict on the name of Smith's attorney, identifying him as 'Michael Reed' in Doc 1 and 'Robert Grass' in Doc 5.\"\n}"
    },
    {
      "id": 232,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Paraguay election, Ecuador assassination, UK politics, Gabon coup) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 2,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states a civilian bystander shot himself, while Doc 3 states the soldier shot himself, creating a factual contradiction about the same event.\"\n}"
    },
    {
      "id": 244,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (Dutch repatriation, Venice UNESCO status, Indian parliament inauguration, and movie bans in Muslim-majority countries) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 133,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the head of Polandâ€™s legal service was fired, while Doc 3 claims they were promoted.\"\n}"
    },
    {
      "id": 175,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 contains a factual contradiction with Doc 1 by stating 'The situation is being investigated,' while Doc 1 says 'The situation is being investigated,' but Doc 3 incorrectly says 'The situation is being investigated,' police denied.\"\n}"
    },
    {
      "id": 166,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a cultural festival clash in Sweden, an Alaska Airlines incident, Sam Bankman-Fried's legal issues, an Iranian execution, and a pilot's alleged sabotage), with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 8,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that Minsk is the Belarusian capital, while Doc 3 claims it is not.\"\n}"
    },
    {
      "id": 81,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"The judge is stated to have said either 'prosecutors' or 'defense attorneys' did not substantiate the need for detention, which are contradictory claims.\"\n}"
    },
    {
      "id": 144,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 136,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"The documents contradict on whether the threat to the Canadian Indian diaspora is as described by New Delhi (Doc 3) or Ottawa (Doc 5).\"\n}"
    },
    {
      "id": 185,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Brazilian court ruling, Japanese military shooting, Sara Sharif case, Sweden terrorism alert) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 70,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 209,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (fire in Vietnam, boat fire in Egypt, mid-air collision in Ukraine, and migrant boat capsizing in the English Channel) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 72,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (movie bans in Muslim-majority countries, UNESCO's concerns about Venice, India's new parliament inauguration, and Miss Universe's Indonesia chapter scandal) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 278,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events.\"\n}"
    },
    {
      "id": 39,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 contradict each other regarding the likelihood of finding more survivors, with Doc 2 stating 'minimal' chances and Doc 5 stating 'substantial' chances.\"\n}"
    },
    {
      "id": 72,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 attributes the 2021 suggestion to ban large cruise ships in Venice to the European Union, while Doc 3 attributes it to UNESCO.\"\n}"
    },
    {
      "id": 107,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states that legislators nominated Srettha Thavisin, while Doc 5 claims opposition leaders did so, creating a factual contradiction about who nominated him.\"\n}"
    },
    {
      "id": 150,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states that the foreign ministers of Hungary and Poland were not at the Kyiv gathering, while Doc 5 states they attended.\"\n}"
    },
    {
      "id": 2,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events in Uganda, Ukraine, and Pakistan.\"\n}"
    },
    {
      "id": 91,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (US debt ceiling, South Africa's Zuma, Gabon coup, and Germany's Nazi symbol case) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 282,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different countries and geopolitical contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 213,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train crash in Italy, gas station explosions in Romania, F-35 crash in South Carolina, and seismic activity in Campi Flegrei) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 33,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states no fatalities occurred in the Annecy attack, while Doc 5 claims several people were killed.\"\n}"
    },
    {
      "id": 285,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 268,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (terrorism concerns in Sweden, climate protests in Italy, a child abuse case, and a cultural festival clash in Sweden), with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 256,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents do not describe the same event or entity with conflicting factual claims.\"\n}"
    },
    {
      "id": 14,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and individuals with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 9,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Documents 4 and 5 contradict each other regarding the location of the Israeli military raid, with Doc 4 stating it occurred in Nablus and Doc 5 stating it occurred in Jenin.\"\n}"
    },
    {
      "id": 96,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 and Doc 4 contradict each other regarding the number of casualties in the attack on the Chinese engineers' convoy, with Doc 3 stating four Chinese engineers and nine Pakistani security forces were killed, and Doc 4 stating no Chinese nationals were killed.\"\n}"
    },
    {
      "id": 187,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (US lab-grown meat approvals, Russian asset seizures, Meta data fine, Google adtech investigation) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 151,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states a post-mortem examination will be conducted, while Doc 5 states it will not be conducted.\"\n}"
    },
    {
      "id": 271,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states the 'civilian government refused to reinstate Bazoum,' while Doc 4 states the 'junta refused to reinstate Bazoum,' creating a factual contradiction about which entity made the decision.\"\n}"
    },
    {
      "id": 108,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states India is the fourth country to achieve a soft moon landing, while Doc 5 claims India is the first country to achieve a soft moon landing near the South Pole, contradicting the count of successful lunar landings.\"\n}"
    },
    {
      "id": 241,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 reports two pilots dead in a plane crash near Karystos on Evia, while Doc 5 reports 18 bodies found in northern Greece near Evros, indicating conflicting events involving fatalities in different locations.\"\n}"
    },
    {
      "id": 160,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe different events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 219,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Quran burning protest in Sweden, release of El Chapo's wife, vehicle attack in Nottingham, and sentencing of a Proud Boys leader) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 275,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents are consistent in their factual descriptions of India's Aditya-L1 mission and other unrelated events.\"\n}"
    },
    {
      "id": 236,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a mine fire in Peru, a typhoon in China, a jet crash in Italy, and a gas station explosion in Russia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 231,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states First Republic Bank had assets of $233 billion but not as of the end of March, while Doc 3 states it had assets of $233 billion as of the end of March.\"\n}"
    },
    {
      "id": 176,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states US defense officials confirmed Patriots were hit by Russia, while Doc 4 claims they confirmed Patriots were not hit.\"\n}"
    },
    {
      "id": 144,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents about the same event or entity.\"\n}"
    },
    {
      "id": 290,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train derailment in Pakistan, coal mine fire in Kazakhstan, earthquake in Morocco, wildfires in Greece) and do not contradict each other on factual details.\"\n}"
    },
    {
      "id": 240,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukraine-Britain relations, Poland-Ukraine historical tensions, Canada-China diplomatic row, and France's evacuation in Niger) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 200,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states the sentencing was made by a federal judge, while Doc 3 states it was made by a Pittsburgh jury, creating a factual contradiction about who made the sentencing decision.\"\n}"
    },
    {
      "id": 99,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 4 contains a factual contradiction with Doc 3 by stating 'nearly no decade of civil war' instead of 'nearly a decade of civil war.'\"\n}"
    },
    {
      "id": 5,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Uganda's anti-LGBTQ+ bill, Brazil's political unrest, the Proud Boys sentencing, and an attack on Israeli tourists in Egypt) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 218,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        3,
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4, 5],\n  \"reason\": \"Documents 3 and 4 describe a 6.8 magnitude earthquake in Morocco, while Document 5 describes two 6.3 magnitude earthquakes in Afghanistan, creating a factual contradiction about the location and magnitude of the events.\"\n}"
    },
    {
      "id": 5,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 17,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and individuals without factual contradictions.\"\n}"
    },
    {
      "id": 155,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states that Major General Zaw Min Tun refuted the incident, while Doc 5 states he confirmed it.\"\n}"
    },
    {
      "id": 214,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 71,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 152,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (wildfires, migrant boat capsizing, earthquakes in Afghanistan, and typhoon in China) and do not contradict each other on factual details about the same event or entity.\"\n}"
    },
    {
      "id": 290,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Documents 2 and 3 contradict each other regarding the cause of the fire in the coal mine in Kazakhstan, with Doc 2 stating it was not caused by methane gas and Doc 3 stating it was.\"\n}"
    },
    {
      "id": 269,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states the judge pushed back on Ferrier's framing of her actions, while Doc 4 says the judge pushed back on the prosecutor's framing of her actions.\"\n}"
    },
    {
      "id": 170,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a refugee shipwreck, a bus crash in Mexico, a school fire in Guyana, and a hurricane in Acapulco) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 147,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 20,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Documents 3 and 5 contradict each other regarding whether the Guyanese government delayed or mobilized a 'full-scale medical evacuation-supported response' after the fire.\"\n}"
    },
    {
      "id": 74,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states 'No fatalities have been reported in Hebei have died in Hebei, officials say,' while Doc 3 states 'At least nine people have died in Hebei, officials say,' creating a factual contradiction about the number of fatalities in Hebei.\"\n}"
    },
    {
      "id": 104,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Poland's referendum on migration, Austria's legal case against Kurz, a synagogue attack in Berlin, and an espionage case in China) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 97,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 4,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 describes the explosion as 'minor,' while Doc 4 describes it as 'massive,' creating a factual contradiction about the severity of the same event.\"\n}"
    },
    {
      "id": 111,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents about the same events or entities.\"\n}"
    },
    {
      "id": 240,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states Britain 'withheld GBP 2.3 billion worth of military support to Ukraine in 2022,' while Doc 2 states Britain 'provided GBP 2.3 billion worth of military support to Ukraine in 2022,' creating a direct factual contradiction.\"\n}"
    },
    {
      "id": 19,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states Roman Protasevich 'is not a dissident blogger,' while Doc 5 describes him as a 'dissident blogger,' creating a factual contradiction about his identity.\"\n}"
    },
    {
      "id": 139,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other3",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 132,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions between them.\"\n}"
    },
    {
      "id": 148,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states 'Ten people were saved' while Doc 2 states 'Ten people were killed,' creating a factual contradiction about the outcome of the church roof collapse.\"\n}"
    },
    {
      "id": 43,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "news2_conflict",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states that 46 women inmates were killed, while Doc 3 states that 41 inmates were killed, creating a factual contradiction about the death toll in the same event.\"\n}"
    },
    {
      "id": 16,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Turkish elections, South African parole, New Zealand minister resignation, Bosnian political crisis) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 62,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 37,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"The sentences differ in a factual claim about Annick Cizel's statement, with Doc 2 stating she 'dismissed' the point and Doc 5 stating she 'pointed out' it.\"\n}"
    },
    {
      "id": 125,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and individuals without factual contradictions.\"\n}"
    },
    {
      "id": 212,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that ZANU-PF supporters celebrated Mnangagwa's win, while Doc 2 claims opposition supporters celebrated, creating a factual contradiction about which group cheered at the results center.\"\n}"
    },
    {
      "id": 191,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "news2_conflict",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Documents 2 and 3 contradict each other regarding whether 'Barbie' stars Margot Robbie and Ryan Gosling.\"\n}"
    },
    {
      "id": 26,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 refers to a 'Dakar civil court' handing down the verdict, while Doc 5 refers to a 'Dakar criminal court,' creating a factual contradiction about the type of court involved in the same event.\"\n}"
    },
    {
      "id": 115,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 283,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states Kristersson will 'ignore both the current legal options and the necessary changes in the law,' while Doc 4 states he will 'discuss both the current legal options and the necessary changes in the law.'\"\n}"
    },
    {
      "id": 71,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"The documents name different provincial police chiefs (Asad Khan in Doc 3 and Akhtar Hayat in Doc 5) as the source of the statement that the explosion was caused by a suicide bomb, which is a factual contradiction.\"\n}"
    },
    {
      "id": 73,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe separate events in different locations (West Bank, Lebanon, and North Korea) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 284,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (migrant truck accident in Mexico, wildfires in Greece, floods in Rwanda, fishing vessel capsizing in the Indian Ocean) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 95,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 and Doc 5 both describe a suspected airstrike in Ethiopia's Amhara region that killed 26 people, but Doc 5 incorrectly refers to the 'Ethiopian Humanitarian Control Council (EHRC)' instead of the correct 'Ethiopian Human Rights Commission (EHRC)' mentioned in Doc 3, creating a factual inconsistency in the name of the organization.\"\n}"
    },
    {
      "id": 201,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (gas explosion in China, bus crash in Mexico, wildfires in multiple regions, coal mine fire in Kazakhstan) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 89,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that Saudi Arabia and the UAE 'implemented edits' before releasing the movie, while Doc 2 claims they 'rejected edits', creating a factual contradiction about the censorship process.\"\n}"
    },
    {
      "id": 155,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 222,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states two men from Afghanistan were 'convicted' of being ISIL agents and executed, while Doc 3 claims they were 'acquitted' but still executed, presenting a factual contradiction.\"\n}"
    },
    {
      "id": 80,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions.\"\n}"
    },
    {
      "id": 128,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Somalia banning apps, JPMorgan acquiring First Republic, FTC appealing Microsoft's acquisition, Apple's stock drop due to China's iPhone ban) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 152,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe the same event with consistent factual information about the earthquakes in Afghanistan.\"\n}"
    },
    {
      "id": 151,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 82,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 128,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Documents 4 and 5 present contradictory statements about the nature of the relationship between the West and China, describing it as a 'technology partnership' versus a 'technology war.'\"\n}"
    },
    {
      "id": 124,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (refugee boat disaster, flooding in southern Europe, fire on a diving boat in Egypt, F-35 crash in South Carolina) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 249,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe separate events (a shark attack in Egypt, a bus crash in Canada, a bus crash in Mexico, and a dam collapse in Norway) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 216,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that the decision is the biggest shake-up since Russia 'ended' its invasion in February 2022, while Doc 4 claims it is the biggest shake-up since Russia 'launched' its invasion in February 2022, which is a factual contradiction regarding the timeline of the invasion.\"\n}"
    },
    {
      "id": 272,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states the cause of the crash is under investigation, while Doc 5 claims pilot error was determined to be the cause.\"\n}"
    },
    {
      "id": 68,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"The conflicting documents provide different names for the UN Human Rights spokesperson who called for a moratorium on Singapore's drug-related executions: 'Ravina Shamdasani' (Doc 3) vs. 'Michelle Bachelet' (Doc 2).\"\n}"
    },
    {
      "id": 215,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (World Scout Jamboree relocation, Burning Man festival flooding, F-35 crash, and church roof collapse) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 36,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states 10 other passengers were rescued, while Doc 4 states 12 other passengers were rescued, creating a factual contradiction about the number of rescued British tourists.\"\n}"
    },
    {
      "id": 109,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "news2_para",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (art repatriation in the Netherlands, Ukraine's statue renovation, British Museum scandal, and movie bans in Muslim-majority countries) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 259,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (India's Rahul Gandhi defamation case, Croatia-Greece football violence, Libya's Derna flood aftermath, and Germany's ban on a neo-Nazi group) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 168,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "other1",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 55,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving U.S.-China tensions, the BRICS summit, and a Chinese spy balloon, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 279,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 contains a contradictory statement by Mike Vigil, claiming the extradition 'took longer than usual' and 'happened quicker than normal,' which is logically inconsistent, while Doc 1 only states it 'happened quicker than normal.'\"\n}"
    },
    {
      "id": 158,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 incorrectly states that Reuters said 'Issam Abdallah was not our videographer,' while Doc 4 correctly states that he was their videographer, creating a factual contradiction about his employment status with Reuters.\"\n}"
    },
    {
      "id": 153,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 261,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states Pak Jong Chon was dismissed, while Doc 5 states Pak Su Il was dismissed, presenting conflicting names for the same position.\"\n}"
    },
    {
      "id": 166,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Documents 2 and 5 contradict each other regarding whether Emerson has a valid license to fly airline planes.\"\n}"
    },
    {
      "id": 81,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Colombian president's son, American citizen in China, Sara Sharif case, Russian journalist) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 53,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (U.S. chemical weapons destruction, Chinese spy balloon, Libya-Israel meeting, and Russia's nuclear test ban treaty revocation) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 87,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 113,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Gabonese coup, Ukrainian defense minister replacement, Afghan school poisoning, Russian espionage case) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 112,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities with no factual contradictions.\"\n}"
    },
    {
      "id": 49,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Thai elephant repatriation, Quran desecration tensions, North Korean missile launches, and South China Sea incident) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 47,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe different events (Nottingham attack, Ovidio GuzmÃ¡n extradition, UK-Rwanda asylum plan, and German neo-Nazi ban) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 101,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states Mukhtar said there are 17 churches in Jaranwala, while Doc 3 states Mukhtar denied there are 17 churches in Jaranwala.\"\n}"
    },
    {
      "id": 219,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Quran burning protest in Sweden, Emma Coronel's release, vehicle attack in Nottingham, and Proud Boys sentencing) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 287,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 1,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states that Avianline Charter denied a tentative version of events, while Doc 5 states that Avianline Charter offered a tentative version of events.\"\n}"
    },
    {
      "id": 189,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "news2_conflict",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 incorrectly states the training area in Vilnius is less than 200 kilometers from Kaliningrad, whereas Doc 1 correctly identifies the training area as Pabrade, which is less than 200 kilometers from Kaliningrad.\"\n}"
    },
    {
      "id": 281,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 describes the prisoner swap as 'successful,' while Doc 5 describes it as 'failed,' creating a factual contradiction about the outcome of the same event.\"\n}"
    },
    {
      "id": 26,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts with no factual contradictions.\"\n}"
    },
    {
      "id": 15,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Iranian arrest, U.S. citizen's conviction in China, Germany explosion, and Italy's artifact return) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 63,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same events without factual contradictions.\"\n}"
    },
    {
      "id": 277,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents are consistent in their factual descriptions of events and do not contain explicit contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 48,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Brazilian court ruling against Bolsonaro, Portugal's euthanasia law, Pittsburgh synagogue shooting verdict, and US Capitol riot sentencing) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 134,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 254,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 66,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states the Canadair CL-415 'crashed into the hillside,' while Doc 2 says it 'landed into the hillside,' presenting a factual contradiction about the nature of the aircraft's impact.\"\n}"
    },
    {
      "id": 220,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events involving Russia and its geopolitical tensions in different regions.\"\n}"
    },
    {
      "id": 204,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states the early exit was announced early in the afternoon on the seventh day, while Doc 2 claims it was announced late in the evening on the same day.\"\n}"
    },
    {
      "id": 45,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states Turkey 'supported' Sweden's NATO membership bid, while Doc 5 states Turkey 'blocked' the bid, creating a factual contradiction.\"\n}"
    },
    {
      "id": 61,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Australian legislation against Russian embassy, US soldier defecting to North Korea, North Korean missile launches, EU-New Zealand trade deal) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 186,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 190,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries (Greece, Bosnia and Herzegovina, Ecuador, and China) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 88,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 incorrectly attributes the statement about Delta ships and cost reduction to Richard Branson instead of Michael Colglazier, as stated in Doc 1.\"\n}"
    },
    {
      "id": 102,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4, 5],\n  \"reason\": \"Doc 1 and 4 suggest the Luna-25 mission experienced a failed maneuver but did not confirm a crash, while Doc 5 explicitly states the spacecraft crashed onto the Moon's surface.\"\n}"
    },
    {
      "id": 171,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 62,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Uganda, Pakistan, North Korea, and US aid to Ukraine) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 170,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (refugee tragedy in Greece, bus crash in Mexico, school fire in Guyana, and Hurricane Otis in Mexico) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 119,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 4,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the coup 'reinstated ex-president Ali Bongo,' while Doc 5 states the coup 'ousted ex-president Ali Bongo,' creating a factual contradiction about the coup's purpose.\"\n}"
    },
    {
      "id": 126,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that insurgents 'rescued' a boat, while Doc 4 states they 'attacked' it, creating a factual contradiction about the militants' action.\"\n}"
    },
    {
      "id": 223,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Pakistan suicide bombing, Nagorno-Karabakh dissolution, Gaza hostages, and Syria airstrikes) and do not contradict each other on factual claims about the same event or entity.\"\n}"
    },
    {
      "id": 87,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states Villavicencio complained of threats, while Doc 5 states he denied receiving threats.\"\n}"
    },
    {
      "id": 271,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Niger-France tensions, Libya-Israel meeting, Russia-North Korea-Belarus relations, and U.S.-China spy balloon incident) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 93,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe different events (wildfires in Canada, Hawaii, and Spain; a nursing home fire in Italy; floods in China; and earthquakes in Afghanistan) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 68,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (car crash in London, drug-related executions in Singapore, Quran burning protest in Sweden, and euthanasia law in Portugal) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 276,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states Kolomoyskyi was 'widely believed to have funded extremist private militia armies,' while Doc 5 claims he 'was never believed widely believed to have funded' them, creating a direct factual contradiction.\"\n}"
    },
    {
      "id": 129,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe the same event without factual contradictions; they provide consistent information about the timeline and details of Sara Sharif's case.\"\n}"
    },
    {
      "id": 263,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events without overlapping claims.\"\n}"
    },
    {
      "id": 250,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states Russia's embassy is in the suburb of Griffith, while Doc 5 claims it is not in Griffith.\"\n}"
    },
    {
      "id": 260,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe the same event with consistent details about the attack on the Novorossiysk naval base and the involvement of two Russian warships.\"\n}"
    },
    {
      "id": 64,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states that Gov. Abbott did not intend to comply with the DOJ's request to remove the buoys, while Doc 5 claims he agreed to comply.\"\n}"
    },
    {
      "id": 156,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries (Greece, Thailand, Israel, Paraguay) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 24,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (New Zealand ministerial resignation, US debt ceiling bill, Greek political ban, and Biden's UAW visit) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 17,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states Leung was 'granted political rights for life,' while Doc 3 states he was 'deprived of political rights for life,' creating a factual contradiction about the outcome of his sentencing.\"\n}"
    },
    {
      "id": 199,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (U.S.-Iran financial deal, Poland-Belarus tensions, Russia's nuclear treaty revocation, and U.S. military aid to Taiwan) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 42,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 47,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (vehicle attack in Nottingham, extradition of Ovidio GuzmÃ¡n LÃ³pez, UK-Rwanda asylum plan ruling, and ban of Artgemeinschaft in Germany) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 228,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"The documents contradict on who called 911 to report a knife attack: Doc 2 says the man called to report his landlord attacked him, while Doc 5 says the woman called to report her landlord attacked her.\"\n}"
    },
    {
      "id": 69,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that Nicolas Petro 'received' money from drug traffickers, while Doc 4 claims he 'refused' it, creating a factual contradiction about his actions.\"\n}"
    },
    {
      "id": 188,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states the arrested individuals did not include the restaurant's manager, employees, or shareholders, while Doc 4 states they did.\"\n}"
    },
    {
      "id": 251,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events in different regions and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 74,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (floods in China, migrant boat capsizing in the English Channel, typhoon impact on a Scout Jamboree in South Korea, and earthquakes in Afghanistan) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 157,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 75,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that NATO was not notified about the airspace violation, while Doc 4 claims that NATO was notified.\"\n}"
    },
    {
      "id": 103,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 2 contradicts Doc 1 by stating 'only a few of the member nation militaries are capable of operating with and supporting each other,' whereas Doc 1 states 'all of the member nation militaries are capable of operating with and supporting each other.'\"\n}"
    },
    {
      "id": 84,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that Russia's Luna-25 encountered an 'abnormal situation' during orbit insertion but does not confirm a crash landing, while Doc 2 explicitly mentions that Luna-25 'experienced a crash landing attempt' in the same region as Chandrayaan-3.\"\n}"
    },
    {
      "id": 89,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Algerian movie ban, British Museum scandal, Dutch repatriation, Indian parliament inauguration) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 46,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Libya-Israel meeting, Chinese spy balloon, North Korea missile launches, and U.S.-Qatar-Iran financial agreement) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 273,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents about the same event or entity.\"\n}"
    },
    {
      "id": 7,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe the same event with consistent details about a seven-day ceasefire agreement mediated by South Sudan.\"\n}"
    },
    {
      "id": 198,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Thailand's political developments, New Zealand's justice minister incident, Ecuador's assassination, and California's Senate appointment) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 110,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe separate events in different countries and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 34,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 267,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states Jonathan Franks mentioned King's father is aware of the KCNA report, while Doc 5 states Franks mentioned King's mother is aware.\"\n}"
    },
    {
      "id": 44,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 refers to Ilias Kasidiaris as 'he' while Doc 5 incorrectly refers to him as 'she', creating a factual contradiction about the gender of the individual.\"\n}"
    },
    {
      "id": 137,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events or provide consistent information about the same event.\"\n}"
    },
    {
      "id": 136,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving different countries and issues, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 263,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 attributes the social media statement about the capsized migrant boat to French Prime Minister Elisabeth Borne, while Doc 5 incorrectly attributes the same statement to French Interior Minister GÃ©rald Darmanin.\"\n}"
    },
    {
      "id": 264,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 100,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states the National Police took the suspects to court, while Doc 5 states the Civil Guard did so, creating a factual contradiction about the law enforcement agency involved.\"\n}"
    },
    {
      "id": 182,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states there was 'a lot of heat and heavy fire underneath the underpass,' while Doc 5 claims 'there was no indication of heat or heavy fire underneath the underpass.'\"\n}"
    },
    {
      "id": 220,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states Putin denied Russia will abide by U.N. sanctions, while Doc 3 states Putin said Russia will abide by U.N. sanctions.\"\n}"
    },
    {
      "id": 138,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 137,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 and Doc 4 contain conflicting descriptions of Poland's actions toward Kyiv's envoyâ€”'summoned' versus 'dismissed'â€”regarding the same event on Wednesday (Sep 20).\"\n}"
    },
    {
      "id": 79,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Eritrean cultural festival clash in Sweden, Ukrainian corruption case, Ecuadorian political assassination, and Japanese military shooting), with no factual contradictions between them.\"\n}"
    },
    {
      "id": 22,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 16,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or do not contain explicit factual contradictions.\"\n}"
    },
    {
      "id": 46,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 and Doc 3 contain conflicting statements about whether the Chinese spy balloon collected information, with Doc 2 suggesting it did not and Doc 3 suggesting it did.\"\n}"
    },
    {
      "id": 274,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Documents 3 and 5 present conflicting statements by police commissioner Fannie Masemola regarding whether the syndicate was involved in CITs, with Doc 3 stating 'we do deny' and Doc 5 stating 'we do believe.'\"\n}"
    },
    {
      "id": 197,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events without overlapping claims.\"\n}"
    },
    {
      "id": 213,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train crash in Italy, explosions in Romania, F-35 crash in South Carolina, and seismic activity in Campi Flegrei) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 85,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 203,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states Khan 'was removed from office in April last year,' while Doc 5 states he 'remained from office in April last year,' creating a factual contradiction about his status at that time.\"\n}"
    },
    {
      "id": 173,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 245,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Israeli-Palestinian raid, Ugandan terrorist attack, Israeli-Egyptian border incident, and F-16 approval for Ukraine) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 134,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 incorrectly attributes the statement about waiting for Kyiv's plan to the Polish government, while Doc 5 correctly attributes it to the Romanian government.\"\n}"
    },
    {
      "id": 106,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that two Albanian workers told the BBC that timely helicopter arrival could have put out the fire, while Doc 3 states they denied this.\"\n}"
    },
    {
      "id": 94,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states the attacker was arrested, while Doc 2 claims the attackers remain at large.\"\n}"
    },
    {
      "id": 149,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 43,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "news2_para",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states 46 women were killed, while Doc 3 initially reports 46 deaths but later contradicts itself by stating 41 inmates died, creating a factual inconsistency in the death toll.\"\n}"
    },
    {
      "id": 34,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 and Doc 5 contradict each other regarding whether serving as an MP was 'a huge honour' or 'not a huge honour' for Boris Johnson.\"\n}"
    },
    {
      "id": 241,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the vessel was not authorised to fish for neon flying squid and Pacific saury, while Doc 3 states it was authorised to fish for those species.\"\n}"
    },
    {
      "id": 52,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"The documents contradict on which organization controls the 300 centers: Doc 4 says Proges Cooperative, while Doc 5 says CareWell Group.\"\n}"
    },
    {
      "id": 157,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states the money was 'withheld' from a South Korean bank to a bank in Qatar, while Doc 2 states it was 'transferred' from a South Korean bank to a bank in Qatar, creating a factual contradiction about the nature of the financial action.\"\n}"
    },
    {
      "id": 257,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 146,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (explosion in Uzbekistan, fire in Vietnam, typhoon-related relocation in South Korea, and a plane crash in Colombia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 202,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (assassination attempt in Bulgaria, Israeli-Palestinian conflict, border incident between Israel and Egypt, and a car bombing in Russia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 282,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different countries and issues, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 229,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 56,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events involving military aircraft, wildfires, and migrant boat incidents.\"\n}"
    },
    {
      "id": 267,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Texas border barrier lawsuit, Travis King crossing into North Korea, Lyon school kimono incident, and attack on Cuban embassy) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 243,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (January 6 Capitol riot, Portugal's euthanasia law, London car incident, and Japan military shooting) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 208,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 describe the same event but differ in the gender of the Mizoram chief minister Zoramthanga, with Doc 2 referring to 'she' and Doc 5 referring to 'he'.\"\n}"
    },
    {
      "id": 126,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 289,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (UK-Israel relations, Australia-Russia tensions, US-Iran prisoner swap, US rejoining UNESCO) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 251,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 11,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Texas border barrier lawsuit, Iran executions, Ovidio GuzmÃ¡n extradition, and London car crash) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 197,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Documents 3 and 5 contradict each other by naming different New Zealand Prime Ministers (Chris Hipkins vs. Jacinda Ardern) at the time of the EU trade agreement signing.\"\n}"
    },
    {
      "id": 183,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states Berlusconi 'failed to become the head of the country's largest parliamentary majority since World War II,' while Doc 4 states he 'became the head of the country's largest parliamentary majority since World War II,' creating a factual contradiction.\"\n}"
    },
    {
      "id": 159,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 278,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe different events.\"\n}"
    },
    {
      "id": 164,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events or provide consistent information about the same event.\"\n}"
    },
    {
      "id": 164,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 257,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ecuadoran political violence, Kevin Spacey's acquittal, and Imran Khan's arrest) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 109,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "news2_conflict",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"The statements by Hartwig Fischer in Docs 3 and 4 directly contradict each other regarding whether he expressed regret and withdrew remarks about the whistleblower.\"\n}"
    },
    {
      "id": 133,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving different countries and issues (Cuba, Poland, Venezuela, and Eritrea), with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 96,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 attributes the attack statement to the Pakistani government, while Doc 4 attributes the same statement to the separatist group, creating a factual contradiction about the source of the claim.\"\n}"
    },
    {
      "id": 61,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Documents 2 and 3 contradict each other regarding whether the soldier was on a civilian tour of the Demilitarized Zone.\"\n}"
    },
    {
      "id": 21,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Apple stock decline, Meta data fine, Claudia Goldin's Nobel, Microsoft-Activision merger) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 67,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states that Mr. Bazoum's government made Mali a key partner in the fight against Islamist extremism, while Doc 5 states that Niger itself became the key partner.\"\n}"
    },
    {
      "id": 217,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Documents 4 and 5 contradict each other on whether a missile or a drone struck a farm in Poland, killing two people.\"\n}"
    },
    {
      "id": 162,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (Ukrainian peace summit, Russian nuclear treaty withdrawal, China-Afghanistan diplomatic move, Honduras-China diplomatic relations) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 200,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Pittsburgh synagogue attack, Uganda anti-LGBTQ+ bill, Roman Protasevich's pardon in Belarus, Ecuador gang leader transfer, and Ecuador political assassination) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 116,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (China-Afghanistan diplomatic relations, North Korea missile launches, Russia-Abkhazia naval base, and U.S. soldier fleeing to North Korea) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 279,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 120,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states protesters were held back by police barricades and never broke through, while Doc 4 claims they initially held back but later managed to break through.\"\n}"
    },
    {
      "id": 57,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 15,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"The officials quoted as providing the information about the body and suspect differ between the two documents (Markus Schmitz vs. Herbert Reul).\"\n}"
    },
    {
      "id": 246,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "other1",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 describes an explosion in a mosque, while Doc 5 describes a fire, creating a factual contradiction about the nature of the incident.\"\n}"
    },
    {
      "id": 211,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (explosions in Romania, wildfires in multiple countries, a mid-air collision in Ukraine, and an explosion in Uzbekistan) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 35,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that three security forces were martyred during the rescue operation, while Doc 4 claims no members of the security forces were martyred.\"\n}"
    },
    {
      "id": 242,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a shooting in Bangkok, a political case in Belarus, and climate protests in Rome) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 27,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (railway bridge collapse in Mizoram, three-train collision in Odisha, seismic activity at Campi Flegrei, dam collapse in Norway) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 172,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that an investigation into the motives behind the shooting is under way, while Doc 2 claims it is not under way.\"\n}"
    },
    {
      "id": 129,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Sara Sharif case, Singapore drug executions, Berlin synagogue attack, and Iran blasphemy executions) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 239,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (earthquake in Morocco, typhoon in Japan, cyclone in Myanmar/Bangladesh, and a migrant truck accident in Mexico) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 138,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Documents 2 and 3 contradict each other regarding the document issued by China and Syria, with one stating a 'joint statement' and the other a 'joint memorandum.'\"\n}"
    },
    {
      "id": 180,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (climate protests in the Netherlands, attacks on Cuban and Berlin synagogues, and a pilot incident in the U.S.) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 246,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "other1",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 283,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Myanmar political pardons, France stabbing, Sweden gang violence, Mexico journalist murder) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 120,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events in different regions.\"\n}"
    },
    {
      "id": 40,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states Adam Delimkhanov is a State Duma deputy who was wounded, while Doc 4 contradicts this by stating he is not a State Duma deputy.\"\n}"
    },
    {
      "id": 218,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (earthquakes in Morocco and Afghanistan, a train collision in India, and a refugee boat tragedy in Greece) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 227,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 incorrectly states 'No previous female laureates include...' while Doc 4 correctly states 'Previous female laureates include...', creating a factual contradiction about the existence of prior female Nobel Economics laureates.\"\n}"
    },
    {
      "id": 147,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states the Pakistani state 'celebrates' the Prophet's birthday, while Doc 5 claims it 'ignores' the same event, creating a factual contradiction about the state's stance.\"\n}"
    },
    {
      "id": 272,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states the December 11, 2000 Osprey crash in North Carolina was blamed on pilot error, while Doc 5 attributes it to problems with a hydraulic part and a software anomaly.\"\n}"
    },
    {
      "id": 243,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents do not contain explicit factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 113,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that Bongo's associates are 'exonerated' of certain charges, while Doc 5 states they are 'accused' of the same charges, creating a factual contradiction about their legal status.\"\n}"
    },
    {
      "id": 132,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts with no factual contradictions.\"\n}"
    },
    {
      "id": 79,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states that no investigations are underway, while Doc 3 states that investigations are underway, creating a factual contradiction about the status of the investigation following the Eritrea-themed festival clash.\"\n}"
    },
    {
      "id": 179,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (prisoner exchanges, Quran desecration protests, U.S.-Iran prisoner swap, and Chinese spy balloon) without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 77,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Germany banning a far-right group, Italy recovering looted antiquities, France's school dress code issue, and Myanmar's pardons of Aung San Suu Kyi) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 255,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that 'authorities in Krasnodar have found for the assailant,' while Doc 3 states that 'authorities in Krasnodar are looking for the assailant,' creating a factual contradiction about whether the assailant has been found.\"\n}"
    },
    {
      "id": 275,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that Lagrange points are named in honor of Joseph-Louis Lagrange, while Doc 2 claims they are not.\"\n}"
    },
    {
      "id": 94,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 235,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that some people had been rescued and taken to hospital, while Doc 3 claims no people had been rescued and taken to hospital, creating a factual contradiction.\"\n}"
    },
    {
      "id": 244,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that Adani's business empire 'has avoided by allegations of accounting fraud,' while Doc 4 states it 'has been hit by allegations of accounting fraud,' presenting a factual contradiction about the nature of the allegations against Adani.\"\n}"
    },
    {
      "id": 286,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states a bystander was arrested, while Doc 4 states the policeman was arrested, creating a factual contradiction about who was arrested.\"\n}"
    },
    {
      "id": 119,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe different events (Turkey's presidential election, Italy's former PM death, Gabon's military coup, and New Zealand's political scandal) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 60,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe distinct events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 11,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states there are no nationwide protests in Iran, while Doc 3 states there are nationwide protests.\"\n}"
    },
    {
      "id": 191,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "news2_para",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events without overlapping claims.\"\n}"
    },
    {
      "id": 162,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states the treaty has 'fully entered into force,' while Doc 4 claims it 'has never fully entered into force.'\"\n}"
    },
    {
      "id": 140,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 attributes the statement about the Molotov cocktail attack to Cuba's Foreign Minister Bruno Rodriguez, while Doc 4 incorrectly attributes the same statement to Cuban President Miguel DÃ­az-Canel.\"\n}"
    },
    {
      "id": 216,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events in different countries and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 8,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different individuals and countries, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 66,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (wildfires in Greece, a refugee boat tragedy, wildfires in northern Greece with migrant casualties, and floods in China) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 192,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the driver 'began stabbing others,' while Doc 3 states he 'stopped stabbing others,' creating a factual contradiction about the assailant's actions.\"\n}"
    },
    {
      "id": 169,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe different events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 127,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 4 incorrectly attributes statements made by Peter Navarro to Steve Bannon.\"\n}"
    },
    {
      "id": 53,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 2 incorrectly states that the U.S. and Russia had already eliminated their holdings of chemical weapons, while Doc 1 clarifies that the U.S. was the last to complete the task and Russia had already done so in 2017.\"\n}"
    },
    {
      "id": 145,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (volcanic activity in Italy, typhoon in South Korea, train crash in Italy, fishing vessel capsizing in the Indian Ocean) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 131,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Poland-Belarus tensions, Saakashvili's detention, China-Afghanistan diplomatic developments, and Russian naval base in Abkhazia) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 167,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Documents 3 and 5 contradict each other regarding whether the report of a shootout that lured officials was false or legitimate.\"\n}"
    },
    {
      "id": 284,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (migrant truck crash in Mexico, wildfires in Greece, floods in Rwanda, fishing vessel capsizing in the Indian Ocean) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 270,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 121,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states 'Several European countries are also looking at banning them,' while Doc 4 states 'Several European countries have stopped looking at banning them,' creating a factual contradiction about the status of European countries' consideration of disposable vape bans.\"\n}"
    },
    {
      "id": 171,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (German politician arrested for Nazi symbols, Israeli unity government, U.S. media coverage of Biden's UAW visit, U.S. debt ceiling bill) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 161,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Brussels terrorist attack, Russia-Ukraine military developments, Hamas-Israel hostage situation) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 141,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "news1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 5,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that viewers can 'watch it live' on the Virtual Telescope Project's website, while Doc 4 states they should 'ignore it live,' which is a direct factual contradiction.\"\n}"
    },
    {
      "id": 29,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Afghanistan school poisoning, North Korea military changes, Myanmar artillery strike, and Ukraine defense minister change) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 184,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe distinct events and entities.\"\n}"
    },
    {
      "id": 58,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 4,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Sudan conflict, Eritrean asylum seeker clashes in Israel, Russian blogger car bombing, US aid to Ukraine) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 248,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The sentences describe the same event (Peter Murrell's arrest in April) without factual contradiction; one states he was 'taken into custody and released,' while the other states he was 'arrested,' which are consistent.\"\n}"
    },
    {
      "id": 59,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (U.S. nuclear submarine visit to South Korea, French evacuation in Niger, Russian-Belarusian-North Korean relations, Russian naval base in Abkhazia) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 289,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (UK-Israel relations, Australia-Russia tensions, US-Iran prisoner swap, US rejoining UNESCO) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 207,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Virgin Galactic spaceflight, Iraq's Telegram ban, Russia's Luna-25 mission, and North Korea's rocket launch) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 280,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the announcement gave no details on the two previous incidents, while Doc 3 claims it gave detailed information on the two previous incidents.\"\n}"
    },
    {
      "id": 121,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 258,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states the statue is 335ft tall, while Doc 5 states it is 102 meters tall (approximately 334.6ft), but Doc 5 also claims the monument is 61 meters high, creating a factual contradiction about the statue's height.\"\n}"
    },
    {
      "id": 229,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"The documents disagree on who detained the 30-year-old manâ€”police officers (Doc 2) versus bystanders (Doc 5).\"\n}"
    },
    {
      "id": 125,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Documents 2 and 5 contain contradictory statements from the same security official regarding the certainty of Daniel Abed Khalife having inside help from the prison.\"\n}"
    },
    {
      "id": 238,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other3",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states Arman Soldin was not born in Sarajevo, while Doc 5 states he was born in Sarajevo.\"\n}"
    },
    {
      "id": 209,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that tributes are absent for 'Juice' including from Zelensky, while Doc 4 claims tributes are pouring in and Zelensky paid homage.\"\n}"
    },
    {
      "id": 163,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving journalists, military actions, and terrorist attacks in different regions and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 92,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe unrelated events in different countries and contexts.\"\n}"
    },
    {
      "id": 44,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 189,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "news2_para",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 266,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states there was a 'massive deployment of anti-jihadist forces' in Niger before the coup, while Doc 5 claims there was an 'absence of significant anti-jihadist forces.'\"\n}"
    },
    {
      "id": 221,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 225,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Turkey-Iraq airstrikes, Kachin IDP camp attack, Iran shrine shooting, and Afghanistan mosque explosion) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 38,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 247,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states that 'the island does not face increasing military threats from Beijing,' while Doc 5 states that 'the island also faces increasing military threats from Beijing,' creating a direct factual contradiction about Taiwan's military situation.\"\n}"
    },
    {
      "id": 143,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 and Doc 5 contradict each other regarding the date of the relevant transcripts (September 26 vs. September 27).\"\n}"
    },
    {
      "id": 208,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (hurricane in Mexico, bridge collapse in India, train crash in Italy, and refugee boat tragedy in Greece) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 288,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events or entities.\"\n}"
    },
    {
      "id": 23,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (India's solar mission, North Korea's failed rocket launch, and Iraq's Telegram ban) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 28,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that Jovenel MoÃ¯se was assassinated, while Doc 2 claims he peacefully resigned, creating a factual contradiction about the cause of the political crisis in Haiti.\"\n}"
    },
    {
      "id": 124,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe the same event with consistent details about the number of deaths and locations affected by the storm.\"\n}"
    },
    {
      "id": 40,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 and Doc 4 contradict each other regarding the status of Adam Delimkhanov, with one stating he was killed and the other stating he was wounded but alive.\"\n}"
    },
    {
      "id": 145,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (earthquakes at Campi Flegrei, typhoon-related Jamboree relocation, train crash in Italy, fishing vessel capsizing, and volcanic activity analysis) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 6,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states the court decision was 'rejected by a majority of nine to one,' while Doc 4 claims the decision was 'made by a majority of nine to one,' creating a factual contradiction.\"\n}"
    },
    {
      "id": 214,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Documents 2 and 4 contradict each other regarding whether the survivor tried or refused to swim back to SaÃ¯dia.\"\n}"
    },
    {
      "id": 114,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "news2_conflict",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states Russia used its veto power at the UN, while Doc 3 claims Russia used a consensus decision, which is a factual contradiction regarding the method of blocking the proposal.\"\n}"
    },
    {
      "id": 12,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events or provide consistent information about the same event.\"\n}"
    },
    {
      "id": 18,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate incidents (hostel fire in New Zealand, plane crash in Colombia, bus crash in Mexico, and train collision in India) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 195,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and entities without factual contradictions.\"\n}"
    },
    {
      "id": 90,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different individuals and jurisdictions, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 111,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"The documents contradict on whether the meeting between Israeli and Libyan foreign ministers was spontaneous/unplanned or pre-arranged.\"\n}"
    },
    {
      "id": 265,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a capsized fishing vessel, a typhoon in Japan, a church collapse in Mexico, and a military aircraft crash in Australia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 101,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 277,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No explicit factual contradictions exist between the documents about the same event or entity.\"\n}"
    },
    {
      "id": 58,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or do not contain explicit factual contradictions.\"\n}"
    },
    {
      "id": 158,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Lebanon refugee camp clashes, journalist attack in Lebanon, Mali attack, and US aid to Ukraine) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 215,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 and Doc 3 contain a factual contradiction in the statement about Burning Man attendees bringing everything they need to survive, with Doc 2 containing a grammatical error ('thisn't') that changes the meaning to the opposite of Doc 3.\"\n}"
    },
    {
      "id": 193,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Dutch repatriation, Ukraine's statue change, India's parliament inauguration, and Venice's UNESCO status) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 33,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states the attacker was an individual armed with a knife, while Doc 5 claims a group of individuals were armed with a knife, creating a factual contradiction about the number of perpetrators.\"\n}"
    },
    {
      "id": 78,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states police are 'well-trained and trigger-happy,' while Doc 5 states they are 'poorly trained and trigger-happy,' creating a factual contradiction about police training.\"\n}"
    },
    {
      "id": 249,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 and Doc 4 contradict each other regarding the age range of bus passengers, with Doc 2 stating they were between 55 and 88 and Doc 4 stating police denied this.\"\n}"
    },
    {
      "id": 29,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that 13,000 students were sickened in Iran, most of whom were not female, while Doc 2 claims that 13,000 mostly female students were sickened, creating a factual contradiction about the gender of the victims.\"\n}"
    },
    {
      "id": 261,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 276,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 contradict each other regarding the spelling of the oligarch's name, referring to him as 'Ihor Kolomoyskyi' and 'Ihor Kolomoiskyi' respectively, which may indicate a factual inconsistency if they refer to the same individual.\"\n}"
    },
    {
      "id": 195,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that La Jornada correspondents have been 'targeted and murdered' in the past, while Doc 3 claims they have been 'targeted in the past but have been protected,' creating a factual contradiction about the level of protection provided to the journalists.\"\n}"
    },
    {
      "id": 112,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a German politician's arrest, a US debt ceiling bill, Terry Gou's resignation and political candidacy, and a California Senate appointment) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 35,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents; they describe separate events in different locations and contexts.\"\n}"
    },
    {
      "id": 163,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 118,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states the Hong Kong warning level was a downgrade from T10 to T8, while Doc 5 claims it was an upgrade.\"\n}"
    },
    {
      "id": 196,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide paraphrased versions of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 19,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about Roman Protasevich and his pardon in Belarus without factual contradictions.\"\n}"
    },
    {
      "id": 230,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that NicolÃ¡s Petro was arrested early Saturday and charged on Tuesday, while Doc 5 claims the arrest occurred on Saturday, July 29, 2023, with no mention of prior charges.\"\n}"
    },
    {
      "id": 256,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian grain bans, Microsoft-Activision merger, underground school in Kharkiv, and WGA strike) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 148,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate events (church collapse, tornado in Perryton, migrant truck accident, and Hurricane Otis) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 262,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Germany banning a neo-Nazi group, extradition of a drug trafficker, return of looted antiquities to Italy, and arrest of a Ukrainian oligarch) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 231,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Meta data fine, First Republic Bank acquisition, underground school in Kharkiv, and WGA strike) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 225,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states villagers said Turkish warplanes bombed the area multiple times, while Doc 2 states villagers denied this.\"\n}"
    },
    {
      "id": 51,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"Documents 3 and 5 describe the same event (Russian missile attack on Lviv on July 6) with no factual contradictions; they are largely identical in content.\"\n}"
    },
    {
      "id": 115,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states the rigged car was 'not a sedan,' while Doc 3 states it was 'a sedan,' creating a factual contradiction about the vehicle type.\"\n}"
    },
    {
      "id": 98,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 98,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states the 27 EU nations have 'bickered' over migration responsibilities, while Doc 5 claims they have 'agreed' on the issue, presenting a factual contradiction.\"\n}"
    },
    {
      "id": 45,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (U.S. Capitol riot, Haiti president's assassination, Quran burning protest in Sweden, and a UK prison escape) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 102,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4, 5],\n  \"reason\": \"Doc 1 and Doc 4 state that Luna-25 was scheduled to enter pre-landing orbit around the same time as Chandrayaan-3, while Doc 5 states it was not scheduled to do so.\"\n}"
    },
    {
      "id": 130,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (fire in Vietnam, hurricane in Mexico, school fire in Guyana, and explosions in Romania) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 82,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (India-Canada diplomatic tensions, U.S.-Iran prisoner swap, U.S. soldier fleeing to North Korea, and Philippines-China maritime disputes) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 181,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that Assadi was never convicted in Belgium, while Doc 4 claims he was convicted in Belgium in 2021.\"\n}"
    },
    {
      "id": 245,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe the same event with consistent factual details about the casualties and the incident near the Israel-Egypt border.\"\n}"
    },
    {
      "id": 175,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate events (bridge collapse in Finland, hurricane in Mexico, shark attack in Egypt, typhoon in China) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 205,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ecuadorian gang leader transfer, Australian case review, Brazilian coup attempt, and Japanese military shooting) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 217,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 41,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate events (tornado in Perryton, Texas; Cyclone Mocha in Myanmar/Bangladesh; train derailment in Pakistan; and flooding at Burning Man festival in Nevada) and do not contradict each other on factual details about the same event or entity.\"\n}"
    },
    {
      "id": 37,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events or provide consistent information about the same event.\"\n}"
    },
    {
      "id": 142,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe distinct events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 194,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a mass shooting in El Paso, espionage in China, repatriation of antiquities to Italy, and BBC staff misconduct allegations) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 235,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (gas explosion in China, floods in Rwanda and Uganda, wildfires in Greece, and a jet crash in Italy) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 178,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states the IRMCT was established after the Rwanda tribunal wound up, while Doc 3 states the ICTR was established, creating a factual contradiction about the successor entity.\"\n}"
    },
    {
      "id": 196,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states Ukraine points to anti-Ukrainian activities of the Polish authorities after the war, while Doc 5 claims it was before the war.\"\n}"
    },
    {
      "id": 22,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states it was not immediately clear whether the crash was deliberate, while Doc 5 claims it was immediately clear.\"\n}"
    },
    {
      "id": 48,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents are either unrelated or describe the same event without factual contradictions.\"\n}"
    },
    {
      "id": 247,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (North Korea's threats, a prisoner exchange, Honduras-China diplomatic relations, and Quran desecration protests) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 9,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different regions and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 232,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"The documents contradict on the expected closeness of the election contest, with Doc 1 stating an expected close contest and Doc 4 stating an expected contest that would not be close.\"\n}"
    },
    {
      "id": 173,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states more than 2,300 were wounded in the bombings, while Doc 4 claims more than 2,300 were 'unharmed wounded,' which is a factual contradiction.\"\n}"
    },
    {
      "id": 83,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train derailment in Pakistan, church collapse in Mexico, typhoon in China, and train collision in India) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 91,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states that Fridayâ€™s twist resolved a two-year legal wrangle over Zumaâ€™s sentence, while Doc 4 states it continued the legal wrangle.\"\n}"
    },
    {
      "id": 150,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Belgian-Iranian prisoner exchange, EU support for Ukraine, China-Syria partnership, US rejoining UNESCO) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 23,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states Japan was on high alert and ordered its Self Defense Force to shoot down the satellite, while Doc 3 claims South Korea made the same order, creating a factual contradiction.\"\n}"
    },
    {
      "id": 6,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 161,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 238,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other3",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 and Doc 5 both describe an attack on a Russian naval base in Novorossiysk, but Doc 1 states the attack was conducted by Ukraine using sea drones, while Doc 5 describes a missile attack in eastern Ukraine near Bakhmut, implying a different event and perpetrator.\"\n}"
    },
    {
      "id": 198,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Documents 2 and 3 contradict on the name of the Transport and Immigration Minister who resigned over a conflict of interest (David Clark vs. Michael Wood).\"\n}"
    },
    {
      "id": 234,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 77,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states the Thai foreign minister 'said he was in good health and conveyed her willingness to engage in talks,' while Doc 5 says 'Mr Don told journalists she was in good health and conveyed her willingness to engage in talks,' creating a factual contradiction about who conveyed Suu Kyi's willingness to talk.\"\n}"
    },
    {
      "id": 252,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Documents 2 and 3 contradict each other regarding the location of the airbase near the city targeted in a drone strike, with Doc 2 stating it is close to Turkeyâ€™s Incirlik airbase and Doc 3 stating it is close to Russiaâ€™s Hmeimim airbase.\"\n}"
    },
    {
      "id": 21,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or contain no explicit factual contradictions.\"\n}"
    },
    {
      "id": 258,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states the Soviet hammer and sickle was on one of Ukraine's most recognizable landmarks, while Doc 5 explicitly claims it was not.\"\n}"
    },
    {
      "id": 3,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states Quinta Brunson and Brian Tyree Henry were not present at the Met Gala and did not voice support for the strike, while Doc 3 claims they did voice support at the event.\"\n}"
    },
    {
      "id": 104,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the penalty for giving false evidence is up to three years in prison, while Doc 3 states it is up to five years.\"\n}"
    },
    {
      "id": 60,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the Nuclear Consultative Group (NCG) was 'established' by the US and South Korea, while Doc 5 claims it was 'dissolved' by them, creating a factual contradiction.\"\n}"
    },
    {
      "id": 259,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Gandhi was disqualified from Parliament in March after being convicted, while Doc 4 claims he was promoted from Parliament at that time.\"\n}"
    },
    {
      "id": 143,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 7,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (USS Carney missile engagement, Ukrainian missile incident, Pakistan suicide attacks, and Sudan ceasefire agreement) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 226,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Kharkiv is Ukraineâ€™s second-largest city, while Doc 4 explicitly contradicts this by stating it is not.\"\n}"
    },
    {
      "id": 78,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 204,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (typhoon-related relocation of a Scout Jamboree, shark attack in Egypt, boat fire in Egypt, and earthquakes in Afghanistan) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 206,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 incorrectly attributes the statement 'He called the Ecuadorian government incompetent' to 'He' (referring to Correa), whereas Doc 1 correctly attributes it to 'Gonzalez'.\"\n}"
    },
    {
      "id": 1,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states the children were found alive and unharmed based on reports from local indigenous communities, while Doc 5 clarifies that the Colombian military and OPIAC have not confirmed contact with the children, only that they may have been sighted but not yet rescued.\"\n}"
    },
    {
      "id": 70,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states Jamal Khashoggi 'was never found and whose fate remains unknown,' while Doc 4 claims he was 'killing and dismemberment,' implying his body was found and disposed of.\"\n}"
    },
    {
      "id": 239,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 mentions Cyclone Vayu causing flooding, while Doc 5 refers to Cyclone Mocha as the cause of the same flooding, indicating a factual contradiction about the cyclone responsible for the event.\"\n}"
    },
    {
      "id": 228,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 59,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (South Korea-U.S. nuclear submarine deployment, Niger coup and evacuation, Russia-Belarus-North Korea relations, Russian naval base in Abkhazia) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 49,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Thai elephant repatriation, Quran desecration tensions, North Korean missile launches, and South China Sea incident) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 226,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian underground school, Somali app ban, WGA strike, Apple stock decline) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 182,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe different events or provide consistent details about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 67,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events in different countries and contexts.\"\n}"
    },
    {
      "id": 221,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the coups have strengthened relations between France and the three Sahel nations, while Doc 5 states the coups have strained relations between France and the three Sahel nations.\"\n}"
    },
    {
      "id": 69,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 4 incorrectly states Nicolas Petro used the money to live in a 'northern Vietnamese city of Barranquilla,' whereas Doc 1 correctly identifies Barranquilla as a northern city in Colombia, constituting a factual contradiction.\"\n}"
    },
    {
      "id": 154,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states Saab 'doubts' international cooperation will hand the issue over, while Doc 4 states he 'hopes' it will.\"\n}"
    },
    {
      "id": 20,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate incidents (mine fire in Kazakhstan, bridge collapse in Finland, school fire in Guyana, and earthquake in Morocco) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 106,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (typhoon in China, wildfires in Greece, mine fire in Peru, and flooding in southern Europe) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 54,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states Lucy Frazer denied being assured by Davie that the BBC was investigating swiftly and sensitively, while Doc 5 states she said Davie had assured her of this.\"\n}"
    },
    {
      "id": 212,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Zimbabwean elections, Ecuadorian elections, Bosnian Serb political developments, and Dutch government collapse) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 38,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"The documents contradict on the gender of the stabbing victim who stumbled towards a house, with Doc 3 describing a 'boy' and Doc 5 describing a 'girl'.\"\n}"
    },
    {
      "id": 107,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different individuals and countries, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 262,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 and Doc 5 contradict each other by using the terms 'return' and 'confiscation' to describe the same event, implying different legal and procedural actions.\"\n}"
    },
    {
      "id": 266,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 156,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe different events in Greece, Thailand, Israel, and Paraguay.\"\n}"
    },
    {
      "id": 50,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Georgian politics, Niger coup, Thai elephant repatriation, and U.S. nuclear submarine in South Korea) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 242,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe distinct events.\"\n}"
    },
    {
      "id": 117,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents are consistent: Biggs and three others were found guilty of seditious conspiracy, while Pezzola was acquitted of that charge but convicted of other charges, as both documents confirm.\"\n}"
    },
    {
      "id": 255,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe separate events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 88,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 116,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Documents 2 and 3 contradict each other on whether Japanâ€™s Ministry of Defense reported that North Korea launched two ballistic missiles on Wednesday night.\"\n}"
    },
    {
      "id": 269,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a stabbing in France, an arrest in Ukraine, a ricin letter to Trump, and a UK-Rwanda asylum policy ruling) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 110,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states the shooter killed himself after the attack, while Doc 4 claims he was apprehended by police.\"\n}"
    },
    {
      "id": 139,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other3",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states Franceâ€™s military presence in Niger was not in response to a request from Nigerâ€™s government, while Doc 5 claims it was in response to a request from Nigerâ€™s government at the time.\"\n}"
    },
    {
      "id": 10,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents about the same event or entity.\"\n}"
    },
    {
      "id": 237,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 refer to the same event (the execution of an Iranian-Swedish dual national for the 2018 military parade attack) but provide conflicting names for the individual: 'Farajollah Chaâ€™ab' in Doc 2 and 'Farajollah Kha'ab' in Doc 5.\"\n}"
    },
    {
      "id": 188,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Burning Man festival, Morocco earthquake, Yinchuan gas explosion, and Espoo bridge collapse) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 177,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states the issue has divided Portugal, while Doc 2 claims it has united the country, representing a factual contradiction about public sentiment.\"\n}"
    },
    {
      "id": 18,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that Tala Sili denied falling onto a roof two floors below, while Doc 2 states that he said he did fall onto such a roof.\"\n}"
    },
    {
      "id": 65,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"Both documents describe the same event and provide consistent information about Qin Gang's removal as foreign minister.\"\n}"
    },
    {
      "id": 32,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (earthquake in Morocco, shark attack in Egypt, typhoon in China, and plane crash in Colombia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 24,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states no senators opposed the bill's passage until the end, while Doc 5 states several senators from both parties still opposed it until the end.\"\n}"
    },
    {
      "id": 165,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 5 states that 'millions received the promised aid deliveries on Saturday,' while Doc 3 says 'trucks carrying relief... are still stuck on the Egyptian side of the Rafah border crossing into Gaza,' indicating a factual contradiction about whether aid was successfully delivered.\"\n}"
    },
    {
      "id": 55,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states analysts denied the public debate was an unwelcome development for the Kremlin, while Doc 5 states analysts said it was an unwelcome development.\"\n}"
    },
    {
      "id": 36,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate events (a fire on a dive boat in Egypt, a tornado in Texas, a mine fire in Kazakhstan, and a plane crash in Greece), and there are no factual contradictions between them.\"\n}"
    },
    {
      "id": 233,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 2 states that the person who organized the attack 'lacked enough information about the route of Geshev,' while Doc 1 states the opposite, that the organizer 'had enough information about the route of Geshev.'\"\n}"
    },
    {
      "id": 25,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states that seven call-center employees vanished in Jalisco on May 20, while Doc 5 explicitly claims it was not reported that they vanished.\"\n}"
    },
    {
      "id": 41,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that the missing person is identified as Ruben Villegas, while Doc 4 explicitly states the missing person is not identified as Ruben Villegas.\"\n}"
    },
    {
      "id": 274,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 51,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (military coup in Gabon, religious violence in Pakistan, and Russian attacks in Ukraine) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 13,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents are consistent in describing the diplomatic expulsions between Canada and China, with no explicit factual contradictions.\"\n}"
    },
    {
      "id": 194,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Crusius targeted El Paso to dissuade Asian immigrants, while Doc 4 states he targeted them to dissuade Hispanic immigrants.\"\n}"
    },
    {
      "id": 224,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "other1",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states 'No shots were fired in two different places in the city,' while Doc 5 states 'Shots were fired in two different places in the city.'\"\n}"
    },
    {
      "id": 270,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 and Doc 4 describe the same event (Somalia banning apps) but disagree on the name of the banned betting website (1XBet vs. Bet365).\"\n}"
    },
    {
      "id": 205,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states Ecuador 'transferred' the gang leader to a maximum security prison, while Doc 2 claims Ecuador 'released' him, which is a factual contradiction regarding the nature of the action taken.\"\n}"
    },
    {
      "id": 254,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Rutte said, 'I have thought about it,' while Doc 4 states he said, 'My advisors have thought about it,' creating a factual contradiction about who considered his decision to retire.\"\n}"
    },
    {
      "id": 285,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 114,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "news2_para",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (UN sanctions in Mali, Israeli-Libyan ministerial meeting, Canada-India tensions, and Quran desecration in Sweden) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 288,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events in different countries and contexts.\"\n}"
    },
    {
      "id": 10,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events involving different individuals and locations.\"\n}"
    },
    {
      "id": 140,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Cuban embassy attack, espionage case in China, Palestinian hunger strike, and Libya flood aftermath) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 123,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states a school administrator plans to file the complaint, while Doc 2 states a human rights lawyer plans to file it, creating a factual contradiction about who is responsible for the complaint.\"\n}"
    },
    {
      "id": 165,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 169,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 281,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 39,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian Air Force collision, refugee boat disaster, Norwegian dam collapse, British tourists missing in Egypt, and EU refugee tragedy) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 183,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (military coup in Gabon, death of Silvio Berlusconi, Paraguayan election, and return of Thaksin Shinawatra to Thailand) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 174,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 103,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 268,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states al-Qaeda condemned attacks against Sweden, while Doc 5 states al-Qaeda called for attacks against Sweden.\"\n}"
    },
    {
      "id": 265,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 incorrectly states that snow pelted the areas, while Doc 5 correctly states that rain pelted the areas during the typhoon in Japan.\"\n}"
    },
    {
      "id": 100,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 12,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that Jewish worshippers attend the annual pilgrimage to the Ghriba synagogue, while Doc 4 claims they do not.\"\n}"
    },
    {
      "id": 54,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (BBC sexual misconduct allegations, Bangkok shooting, Libya floods, Ecuador prison deaths) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 253,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states Rutte submitted his resignation for the third time, while Doc 5 claims it was the first time.\"\n}"
    },
    {
      "id": 185,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents about the same event or entity.\"\n}"
    },
    {
      "id": 31,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states that archosaurs 'also excluded dinosaurs and pterosaurs,' while Doc 4 states that archosaurs 'also included dinosaurs and pterosaurs,' creating a factual contradiction about the relationship between archosaurs and these extinct species.\"\n}"
    },
    {
      "id": 250,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 211,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states 'dozens have suffered horrifying burns' while Doc 3 claims 'hundreds have suffered horrifying burns' regarding the same event in Romania.\"\n}"
    },
    {
      "id": 50,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states 'Kyiv' has been battling a Russian invasion, while Doc 3 states 'Warsaw' has been battling a Russian invasion, which is a factual contradiction regarding the country involved in the conflict.\"\n}"
    },
    {
      "id": 122,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 30,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Documents 1 and 5 contradict each other regarding Judge Tom Bathurst's conclusion on reasonable doubt in Kathleen Folbigg's case.\"\n}"
    },
    {
      "id": 177,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 4,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 117,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (school dress code in France, Proud Boys sentencing, climate protests in the Netherlands, and a military shooting in Japan) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 86,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states the government mobilised more helicopters for evacuations, while Doc 3 states they mobilised more boats, creating a factual contradiction about the type of vehicles used.\"\n}"
    },
    {
      "id": 280,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (bus crash in Mexico, F-35 crash in South Carolina, train collision in India, and mine fire in Kazakhstan) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 146,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states flights were suspended at Tashkent's international airport, while Doc 2 states flights were operating as normal at the same airport.\"\n}"
    },
    {
      "id": 187,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 4 contradicts Doc 1 by stating that GOOD Meat received final USDA approval but is 'denied for sale in the U.S.', whereas Doc 1 states it is approved for sale.\"\n}"
    },
    {
      "id": 192,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents about the same event or entity.\"\n}"
    },
    {
      "id": 264,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states a 'Malaysian company' runs the Malaysia pageant, while Doc 5 claims the 'Indonesian company' runs it, creating a factual contradiction about the entity responsible.\"\n}"
    },
    {
      "id": 167,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian drone attack, Brussels shooting, Mexican police massacre, Tel Aviv attack) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 56,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 and Doc 5 contain a factual contradiction in the quoted statement from 'she' regarding the reason for migration from Senegal, with Doc 4 stating 'she denied' and Doc 5 stating 'she added'.\"\n}"
    },
    {
      "id": 160,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Noboaâ€™s approaches to address crime have 'spanned a wide spectrum,' while Doc 4 claims his approaches have been 'limited to a single strategy.'\"\n}"
    },
    {
      "id": 135,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states Hengaw denied security forces opened fire in Mahabad, while Doc 3 states Hengaw said security forces did open fire there.\"\n}"
    },
    {
      "id": 80,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states Navalny pleaded guilty, while Doc 3 states he pleaded not guilty.\"\n}"
    },
    {
      "id": 252,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events in different regions involving distinct actors and circumstances.\"\n}"
    },
    {
      "id": 286,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Egyptian police attack, El Chapo's wife release, Navalny's sentencing, and Nicola Sturgeon's arrest) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 227,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about Claudia Goldin's Nobel Prize and its implications.\"\n}"
    },
    {
      "id": 153,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states that authorities 'released seven others days later,' while Doc 5 states that 'authorities arrested seven others days later,' creating a factual contradiction about the same event.\"\n}"
    },
    {
      "id": 201,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states the bus driver was 'taken into custody,' while Doc 5 says he was 'released into custody,' creating a factual contradiction about his legal status.\"\n}"
    },
    {
      "id": 13,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Canada-China diplomatic tensions, Australia-Russia embassy issue, and European-Iran prisoner exchanges) with no overlapping factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 184,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving different companies and regulatory actions, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 31,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 179,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that Mr. Vandecasteele was arrested in Brussels in 2022, while Doc 4 states he was arrested in Tehran in 2022, creating a factual contradiction about the location of his arrest.\"\n}"
    },
    {
      "id": 181,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Iraqi-Swedish tensions, North Korea-US tensions, European prisoner exchange, EU-New Zealand trade deal) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 141,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "news1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that Russia's Luna-25 encountered an 'abnormal situation' during orbit insertion but did not specify if the mission was lost, while Doc 5 explicitly mentions that Russia's Luna 25 'experienced a crash landing attempt' in the same region as India's successful landing, implying a definitive failure.\"\n}"
    },
    {
      "id": 28,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Haiti assassination, Croatia fan violence, France vape ban, Poland immigration referendum) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 85,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states local authorities 'continued' public events as a sign of mourning, while Doc 2 states they 'suspended' them, creating a factual contradiction about the same event.\"\n}"
    },
    {
      "id": 168,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other1",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Ivanov wore a black hooded jacket and mask during the hearing, while Doc 4 states Kurmasheva wore the same outfit, creating a factual contradiction about the individual's identity.\"\n}"
    },
    {
      "id": 30,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Kathleen Folbigg's pardon, Singapore drug executions, Sweden gang violence, and Rotterdam shooting) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 76,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that four European countries announced evacuation plans, while Doc 4 states they denied such plans.\"\n}"
    },
    {
      "id": 131,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events involving different countries and entities.\"\n}"
    },
    {
      "id": 253,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions.\"\n}"
    },
    {
      "id": 224,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "other1",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 123,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 130,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe different events (fire in Vietnam, hurricane in Mexico, school fire in Guyana, and explosions in Romania) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 223,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Pakistan suicide bombing, Nagorno-Karabakh dissolution, Gaza hostages, and Syria airstrikes) and do not contradict each other on factual claims about the same event or entity.\"\n}"
    },
    {
      "id": 154,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (gang rape in Spain, arrest warrant for GuaidÃ³ in Venezuela, climate protest in Rome, and vape ban in France) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 52,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 32,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (earthquake in Morocco, shark attack in Egypt, typhoon in China, and plane crash in Colombia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 206,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ecuadorian political murders, Portugal's euthanasia law, Venezuela's legal actions against GuaidÃ³, and Italy's repatriation of antiquities) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 248,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and individuals without factual contradictions.\"\n}"
    },
    {
      "id": 186,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Boris Johnson's parliamentary report, Nicola Sturgeon's arrest, a gang rape in Spain, and a shooting in Bangkok) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 176,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents about the same event or entity.\"\n}"
    },
    {
      "id": 174,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 and Doc 5 contradict each other regarding the range and capability of the Taurus cruise missiles, with Doc 1 stating they are long-range and capable of striking Moscow, and Doc 5 stating they are not long-range and not capable of such strikes.\"\n}"
    },
    {
      "id": 149,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Laphonza Butler served as a Regent for the University of California from 2018 to 2021, while Doc 4 incorrectly states 'Johnson' served in the same role during the same period.\"\n}"
    },
    {
      "id": 287,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 127,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 27,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (railway bridge collapse in Mizoram, train collision in Odisha, Campi Flegrei seismic activity, and dam collapse in Norway) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 65,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 199,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 230,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 4,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Documents 2 and 3 contradict each other regarding whether the funeral of Armita Geravand took place or was canceled on Sunday morning.\"\n}"
    },
    {
      "id": 122,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 refers to 'She and his Proud Boys members' while Doc 4 refers to 'He and his Proud Boys members,' creating a factual contradiction about the gender of the individual involved in the Capitol insurrection alongside Enrique Tarrio.\"\n}"
    },
    {
      "id": 14,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Documents 2 and 4 contradict each other regarding the age and gender of the suspect in the Mercedes-Benz factory shooting.\"\n}"
    },
    {
      "id": 86,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate events (floods in Norway, earthquakes in Afghanistan, typhoon in China, and a bus crash in Mexico) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 99,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian-Russia conflict spillover into Romania, military coup in Niger, militia clashes in Libya, and Islamist attacks in Mali) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 84,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states that Telegram is 'restricted for content sharing' in Iraq, while Doc 5 states it is used 'for content sharing', creating a factual contradiction.\"\n}"
    },
    {
      "id": 76,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (U.S. chemical weapons destruction, Russia's nuclear test ban treaty revocation, French evacuation in Niger, and U.S. military aid to Taiwan) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 203,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different individuals and jurisdictions, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 3,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe unrelated events (Ukrainian school construction, WGA strike, lab-grown meat approval, and First Republic Bank acquisition) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 93,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 attributes the siren responsibility to the Maui County Emergency Management Agency, while Doc 2 attributes it to the Hawaii State Emergency Management Agency.\"\n}"
    },
    {
      "id": 64,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 83,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4, 5],\n  \"reason\": \"Doc 1 and Doc 5 state 275 killed in June Odisha train crash, while Doc 4 states 288 killed in the same incident, creating a factual contradiction in the death toll.\"\n}"
    },
    {
      "id": 193,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states the repatriated items include the 'Lombok treasure', while Doc 3 states they exclude it.\"\n}"
    },
    {
      "id": 142,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 237,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 contradict each other regarding whether Finland and Norway condemned or supported the execution of the Iranian-Swedish dual national.\"\n}"
    },
    {
      "id": 207,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the Luna-25 spacecraft 'continued to exist' after colliding with the Moon, while Doc 5 states it 'ceased to exist' after the collision, creating a factual contradiction about the spacecraft's status post-impact.\"\n}"
    },
    {
      "id": 108,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 210,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other3",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 190,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states the Dayton Agreement allows foreign judges to remain indefinitely, while Doc 4 claims it limits them to five years.\"\n}"
    },
    {
      "id": 178,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 97,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train crash in Italy, gas station explosion in Dagestan, wildfires in multiple regions, and warehouse explosion in Uzbekistan) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 73,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that none of UNRWA's schools were damaged in Ain al-Hilweh, while Doc 4 claims two schools were damaged.\"\n}"
    },
    {
      "id": 92,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 105,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states Hilary will no longer be a hurricane when approaching Baja California, while Doc 5 states it will still be a hurricane.\"\n}"
    },
    {
      "id": 159,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states the deployment of soldiers from Operation Sentinelle would be completed by tomorrow evening, while Doc 5 states the withdrawal would be completed by the same time.\"\n}"
    },
    {
      "id": 118,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a typhoon in China, a fire in New Zealand, a plane crash in Australia, and a shipwreck in the Indian Ocean) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 172,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe the same event with consistent factual details or discuss unrelated events.\"\n}"
    },
    {
      "id": 105,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 25,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 135,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Iranian protests, Croatian fan violence, Ecuadorian gang transfer, Brazilian election ruling) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 234,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Khader Adnan had already been tried at the time of his passing, while Doc 4 states he had not yet been tried.\"\n}"
    },
    {
      "id": 42,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe the same event with consistent factual details about the attack, the number of casualties, and the fate of the attackers.\"\n}"
    },
    {
      "id": 63,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 3,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 and Doc 5 contain conflicting reports about whether the AFP news agency reported or denied that a Sweden-based Iraqi refugee stomped on the Quran during a protest in Stockholm.\"\n}"
    },
    {
      "id": 273,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Afghanistan school poisoning, Sudan displacement, Russian espionage case, and Russian missile attack on Lviv) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 57,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states North Korea condemned the US submarine deployment, while Doc 4 claims it welcomed it.\"\n}"
    },
    {
      "id": 260,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 and Doc 5 contradict each other regarding the outcome of the attack on the Russian landing ship 'Olenegorsky Gornyak'â€”Doc 4 states it was damaged and unable to conduct combat operations, while Doc 5 states it was repaired and able to continue its missions.\"\n}"
    },
    {
      "id": 222,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Mexico, Iran, Nagorno-Karabakh, France) with no overlapping factual claims that contradict each other.\"\n}"
    },
    {
      "id": 180,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states police fired water cannon, while Doc 3 claims police withheld water cannon during the same protest event.\"\n}"
    },
    {
      "id": 202,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "other3",
        "news1",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 2,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that armed Israeli settlers had entered the village of Burqa, while Doc 3 claims they had exited the village, creating a factual contradiction about the settlers' presence.\"\n}"
    },
    {
      "id": 90,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states X is previously known as Twitter, while Doc 4 states X is previously known as Instagram, which is factually contradictory.\"\n}"
    },
    {
      "id": 233,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 236,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 1,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that authorities reported 27 deaths from the mine fire, while Doc 2 claims authorities denied the 27 deaths, creating a factual contradiction.\"\n}"
    },
    {
      "id": 75,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "guided",
      "perm_order": [
        "news2_para",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Poland-Belarus tensions, Chinese spy balloon, Russian naval base in Abkhazia, Iran-U.S. prisoner swap) and do not present factual contradictions about the same event or entity.\"\n}"
    }
  ]
}