{
  "overall": 0.7120689655172414,
  "conflict": 0.503448275862069,
  "nonconflict": 0.9206896551724137,
  "results": [
    {
      "id": 95,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 5 attributes the denial of Fano's allegations to the United Nations, while Doc 3 correctly attributes it to Ethiopia's government.\"\n}"
    },
    {
      "id": 210,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities with no factual contradictions.\"\n}"
    },
    {
      "id": 232,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Paraguay election, Ecuador assassination, UK politics, Gabon coup) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 2,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 244,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (Dutch repatriation, Venice UNESCO status, Indian parliament inauguration, and movie bans in Muslim-majority countries) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 133,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that Polandâ€™s foreign ministry 'said on Friday it had fired the head of its legal service,' while Doc 3 claims it 'promoted the head of its legal service,' creating a factual contradiction.\"\n}"
    },
    {
      "id": 175,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 contains a factual contradiction with Doc 1 by stating 'police denied' instead of 'police added' regarding the investigation.\"\n}"
    },
    {
      "id": 166,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a cultural festival clash in Sweden, an Alaska Airlines incident, Sam Bankman-Fried's legal issues, an Iranian execution, and a pilot's alleged sabotage), with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 8,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 3 incorrectly states that Minsk is not the Belarusian capital, contradicting the factual statement in Doc 2 that Minsk is the Belarusian capital.\"\n}"
    },
    {
      "id": 81,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 144,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 136,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 185,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Brazilian court ruling, Japanese military shooting, Sara Sharif case, Sweden terrorism alert) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 70,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving different countries and geopolitical contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 209,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a fire in Vietnam, a boat fire in Egypt, a mid-air collision in Ukraine, and a migrant boat capsizing in the English Channel) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 72,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (movie bans in Muslim-majority countries, UNESCO's concerns for Venice, India's new parliament inauguration, and Miss Universe's Indonesia chapter scandal) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 278,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe different events.\"\n}"
    },
    {
      "id": 39,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states that the chances of finding more survivors are minimal, while Doc 5 claims the chances are substantial.\"\n}"
    },
    {
      "id": 72,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (movie bans in Muslim-majority countries, UNESCO's Venice recommendation, India's new parliament inauguration, and Miss Universe's Indonesia chapter issues) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 107,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions.\"\n}"
    },
    {
      "id": 150,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states that the foreign ministers of Hungary and Poland were not at the Kyiv gathering, while Doc 5 claims they attended.\"\n}"
    },
    {
      "id": 2,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No explicit factual contradictions exist between the documents; they describe separate events in Uganda, Ukraine, and Pakistan.\"\n}"
    },
    {
      "id": 91,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (US debt ceiling, South Africa's Zuma, Gabon coup, and Germany's Nazi symbol case) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 282,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different countries and geopolitical contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 213,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train crash in Italy, gas station explosions in Romania, F-35 crash in South Carolina, and seismic activity in Campi Flegrei) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 33,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states that four children were stabbed and two adults were also attacked, while Doc 5 claims several people were killed in the attack, introducing a factual contradiction about the number of casualties.\"\n}"
    },
    {
      "id": 285,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 268,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (terrorism concerns in Sweden, climate protests in Italy, a child abuse case, and a cultural festival clash in Sweden), with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 256,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian grain bans, Microsoft-Activision merger, underground school in Kharkiv, and WGA strike) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 14,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different individuals and locations, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 9,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Documents 4 and 5 contradict each other regarding the location of the Israeli military raid, with Doc 4 stating it occurred in Nablus and Doc 5 stating it occurred in Jenin.\"\n}"
    },
    {
      "id": 96,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 and Doc 4 contradict each other regarding the number of casualties: Doc 3 claims four Chinese engineers and nine Pakistani security forces were killed, while Doc 4 states no Chinese nationals were killed.\"\n}"
    },
    {
      "id": 187,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (US lab-grown meat approvals, Russia seizing Western company assets, Meta data fine, EU antitrust action against Google) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 151,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states a post-mortem examination will be conducted, while Doc 5 states it will not be conducted.\"\n}"
    },
    {
      "id": 271,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 108,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 contradict each other regarding whether India is the fourth or the first country to achieve a soft moon landing, and whether Russia is among the nations with successful moon landings.\"\n}"
    },
    {
      "id": 241,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 reports two pilots dead in a plane crash in Evia, while Doc 5 reports 18 bodies found in northern Greece, likely migrants, with no mention of the pilots or the Evia crash.\"\n}"
    },
    {
      "id": 160,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe different events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 219,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Quran burning protest in Sweden, Emma Coronel's release, vehicle attack in Nottingham, and Proud Boys sentencing) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 275,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe the same event with consistent factual details or are unrelated to each other.\"\n}"
    },
    {
      "id": 236,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a mine fire in Peru, a typhoon in China, a military jet crash in Italy, and a gas station explosion in Russia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 231,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states First Republic Bank had assets of $233 billion, but not as of the end of March, while Doc 3 claims it had assets of $233 billion as of the end of March.\"\n}"
    },
    {
      "id": 176,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that US defense officials confirmed the Patriot system was hit by Russia, while Doc 4 claims they confirmed it was not hit.\"\n}"
    },
    {
      "id": 144,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 290,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train derailment in Pakistan, coal mine fire in Kazakhstan, earthquake in Morocco, wildfires in Greece) and do not contradict each other on factual details.\"\n}"
    },
    {
      "id": 240,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (UK-Ukraine relations, Poland-Ukraine historical tensions, Canada-China diplomatic tensions, and France's evacuation in Niger) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 200,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Tree of Life shooting, Uganda's Anti-Homosexuality Bill, Roman Protasevich's pardon, Ecuador gang leader transfer) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 99,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 4 states 'nearly no decade of civil war in Libya' which contradicts Doc 3's 'nearly a decade of civil war' as factual descriptions of the duration of the conflict.\"\n}"
    },
    {
      "id": 5,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Uganda's anti-LGBTQ+ bill, Brazil's political unrest, the Proud Boys' seditious conspiracy, and an attack on Israeli tourists in Egypt) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 218,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a refugee boat tragedy, a train collision, and two separate earthquakes in Morocco and Afghanistan) and do not contradict each other factually.\"\n}"
    },
    {
      "id": 5,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 17,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and individuals without factual contradictions.\"\n}"
    },
    {
      "id": 155,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states that Major General Zaw Min Tun denied conducting the attack, while Doc 5 claims he confirmed the incident.\"\n}"
    },
    {
      "id": 214,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Niger evacuation, Morocco-Algeria incident, Ukraine-Poland grain dispute, U.S.-Qatar-Iran financial agreement) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 71,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 152,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (wildfires in Canada, Hawaii, and Spain; a migrant boat capsizing in the English Channel; earthquakes in Afghanistan; and Typhoon Saola in China) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 290,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the fire in the coal mine was confirmed not to have been caused by methane gas, while Doc 3 claims the blaze appeared to have been caused by a pocket of methane gas.\"\n}"
    },
    {
      "id": 269,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states the judge pushed back on Ferrier's framing of her actions, while Doc 4 incorrectly attributes the pushback to the prosecutor.\"\n}"
    },
    {
      "id": 170,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a refugee shipwreck, a bus crash in Mexico, a school fire in Guyana, and a hurricane in Acapulco) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 147,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 20,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the Guyanese government delayed a 'full-scale medical evacuation-supported response,' while Doc 5 states they mobilized such a response after the fire.\"\n}"
    },
    {
      "id": 74,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states 'No fatalities have been reported in Hebei have died in Hebei, officials say,' while Doc 3 states 'At least nine people have died in Hebei, officials say,' creating a factual contradiction about the death toll in Hebei.\"\n}"
    },
    {
      "id": 104,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Poland's referendum on migration, Austria's legal case against Kurz, a synagogue attack in Berlin, and an espionage conviction in China) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 97,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 describes a 'minor explosion' while Doc 4 describes a 'massive explosion' at the same gas station in Dagestan, creating a factual contradiction about the scale of the event.\"\n}"
    },
    {
      "id": 111,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 contradict each other regarding whether the meeting between Israeli and Libyan foreign ministers was spontaneous or pre-arranged.\"\n}"
    },
    {
      "id": 240,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states the UK withheld GBP 2.3 billion in military support to Ukraine in 2022, while Doc 2 states the UK provided GBP 2.3 billion in military support to Ukraine in 2022.\"\n}"
    },
    {
      "id": 19,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that Roman Protasevich 'is not a dissident blogger,' while Doc 5 refers to him as a 'dissident blogger,' creating a factual contradiction about his identity.\"\n}"
    },
    {
      "id": 139,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other3",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 132,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts with no factual contradictions.\"\n}"
    },
    {
      "id": 148,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe different events (church collapse, tornado in Texas, migrant truck accident, and hurricane in Acapulco) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 43,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "news2_conflict",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 and Doc 3 contradict each other regarding the number of victims (46 vs. 41) and the identity of Karla Soriano, with Doc 3 stating she was not the sister of Maribel Euceda.\"\n}"
    },
    {
      "id": 16,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Turkish elections, South African parole, New Zealand ministerial resignation, Bosnian political tensions) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 62,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 37,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events or provide consistent information about the same event.\"\n}"
    },
    {
      "id": 125,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and individuals without factual contradictions.\"\n}"
    },
    {
      "id": 212,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Zimbabwean election, Ecuadorian election, Bosnian political crisis, and Dutch government collapse) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 191,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "news2_conflict",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that the 'Barbie' movie stars Margot Robbie and Ryan Gosling, while Doc 3 claims it does not star them, creating a factual contradiction about the film's cast.\"\n}"
    },
    {
      "id": 26,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts with no factual contradictions.\"\n}"
    },
    {
      "id": 115,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 283,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that Kristersson will 'ignore both the current legal options and the necessary changes in the law,' while Doc 4 states he will 'discuss both the current legal options and the necessary changes in the law.'\"\n}"
    },
    {
      "id": 71,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Documents 3 and 5 provide conflicting death tolls from the same suicide bombing in Pakistan: 44 (Doc 3) vs. 42 (Doc 5).\"\n}"
    },
    {
      "id": 73,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events in different regions (West Bank, Lebanon, and North Korea) without overlapping claims about the same event or entity.\"\n}"
    },
    {
      "id": 284,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (migrant truck accident in Mexico, wildfires in Greece, floods in Rwanda, fishing vessel capsizing in the Indian Ocean) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 95,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 and Doc 5 both describe a suspected airstrike in Ethiopia's Amhara region that killed 26 people, but Doc 5 incorrectly refers to the 'Ethiopian Humanitarian Control Council (EHRC)' instead of the correct 'Ethiopian Human Rights Commission (EHRC)' mentioned in Doc 3, creating a factual inconsistency in the name of the organization.\"\n}"
    },
    {
      "id": 201,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states the bus plunged into a 164-foot-deep hillside, while Doc 5 states it plunged into a 50-meter-deep ravine, which are conflicting measurements.\"\n}"
    },
    {
      "id": 89,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 2 states that Saudi Arabia and the UAE 'rejected edits' before releasing the movie, while Doc 1 states that Saudi Arabia and the UAE 'implemented edits' before releasing the movie, creating a factual contradiction.\"\n}"
    },
    {
      "id": 155,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 222,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that two men from Afghanistan were convicted of being ISIL agents and executed, while Doc 3 claims they were acquitted and executed.\"\n}"
    },
    {
      "id": 80,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions.\"\n}"
    },
    {
      "id": 128,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Somalia banning apps, JPMorgan acquiring First Republic, FTC vs. Microsoft, Apple's stock drop due to China's iPhone ban) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 152,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (wildfires in multiple regions, a migrant boat capsizing, earthquakes in Afghanistan, and a typhoon in China) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 151,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 82,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 128,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Somalia banning apps, JPMorgan acquiring First Republic, FTC vs. Microsoft, Apple stock drop due to Chinese iPhone ban). No factual contradictions about the same event or entity are present.\"\n}"
    },
    {
      "id": 124,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a refugee boat tragedy, flooding in southern Europe, a scuba diving boat fire, and an F-35 jet crash) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 249,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe separate events (a shark attack in Egypt, a bus crash in Mexico, a bus-truck collision in Canada, and a dam collapse in Norway) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 216,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian defense minister change, Jacksonville shooting, Turkey-Iraq airstrikes, and Pakistan suicide bombing) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 272,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states the cause of the crash is under investigation, while Doc 5 claims pilot error was determined to be the cause.\"\n}"
    },
    {
      "id": 68,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (car crash in London, Singapore drug executions, Quran burning protest in Sweden, and euthanasia law in Portugal) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 215,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Scout Jamboree relocation, Burning Man flooding, F-35 crash, church roof collapse) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 36,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate events (boat fire in Egypt, tornado in Texas, mine fire in Kazakhstan, wildfires in Greece) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 109,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "news2_para",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (art repatriation in the Netherlands, Ukraine's statue renovation, British Museum theft scandal, and movie bans in Muslim-majority countries) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 259,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (India's Rahul Gandhi defamation case, Croatia-Greece football violence, Libya's Derna flood aftermath, and Germany's ban on a neo-Nazi group) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 168,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "other1",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 55,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving U.S.-China-Taiwan tensions, South China Sea disputes, the BRICS summit and Putin's non-attendance, and the Chinese spy balloon incident, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 279,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 158,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Lebanon refugee camp clashes, journalist attack in Lebanon, Mali attack, and US aid to Ukraine) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 153,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 261,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 166,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states that Emerson lacked a valid license to fly airline planes, while Doc 5 states that Emerson has a valid license.\"\n}"
    },
    {
      "id": 81,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Colombian president's son, American citizen in China, UK murder investigation, Russian journalist) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 53,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent factual information about the same event without contradiction.\"\n}"
    },
    {
      "id": 87,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different countries and individuals, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 113,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event in Gabon without factual contradictions.\"\n}"
    },
    {
      "id": 112,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (German politician arrested for Nazi symbols, US debt ceiling bill passed, Terry Gou's resignation and political candidacy, and Laphonza Butler's Senate appointment) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 49,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Thai elephant repatriation, Quran desecration tensions, North Korean missile launch, and South China Sea incident) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 47,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (vehicle attack in Nottingham, extradition of Ovidio GuzmÃ¡n, court ruling on Rwanda asylum plan, ban of Artgemeinschaft in Germany) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 101,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that Khalid Mukhtar believes there are 17 churches in Jaranwala, while Doc 3 states that he denied there are 17 churches in Jaranwala.\"\n}"
    },
    {
      "id": 219,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Quran burning protest in Sweden, Emma Coronel's release, vehicle attack in Nottingham, and Proud Boys sentencing) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 287,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 1,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states that Avianline Charter denied a tentative version of events, while Doc 5 states that Avianline Charter offered a tentative version of events.\"\n}"
    },
    {
      "id": 189,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "news2_conflict",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 incorrectly states the training area in Vilnius is less than 200 km from Kaliningrad, whereas Doc 1 correctly identifies the training area as Pabrade, which is less than 200 km from Kaliningrad.\"\n}"
    },
    {
      "id": 281,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states the prisoner swap was successful, while Doc 5 claims it failed, creating a factual contradiction about the outcome of the same event.\"\n}"
    },
    {
      "id": 26,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts with no factual contradictions.\"\n}"
    },
    {
      "id": 15,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Iranian arrest, U.S. citizen's conviction in China, Germany explosion, and Italy's artifact return) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 63,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Iraqi protests over Quran burning, UN sanctions in Mali, Putin's BRICS summit absence, and Libya-Israel meeting) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 277,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents are consistent in their factual descriptions of events and do not contain explicit contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 48,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Brazilian court ruling against Bolsonaro, Portugal's euthanasia law, Pittsburgh synagogue shooting verdict, and US Capitol riot sentencing) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 134,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 254,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 66,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 220,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving Russia and its relations with different countries and international bodies, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 204,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states the early exit was announced early in the afternoon on the seventh day, while Doc 2 states it was announced late in the evening on the same day.\"\n}"
    },
    {
      "id": 45,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 and Doc 5 contradict each other regarding the reason Turkey has blocked Sweden's NATO membership bid, with Doc 3 stating Turkey 'has supported the bid' and Doc 5 stating Turkey 'has blocked the bid'.\"\n}"
    },
    {
      "id": 61,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Australian legislation against Russian embassy, US soldier defecting to North Korea, North Korean missile launches, EU-New Zealand trade deal) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 186,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (UK parliamentary vote on Boris Johnson, Nicola Sturgeon's arrest, gang rape in Spain, and a schoolboy shooting in Bangkok) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 190,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events in different countries (Greece, Bosnia and Herzegovina, Ecuador, and China) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 88,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 incorrectly attributes the statement about Delta ships and cost reduction to Richard Branson instead of Michael Colglazier, as stated in Doc 1.\"\n}"
    },
    {
      "id": 102,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4, 5],\n  \"reason\": \"Doc 1 and 4 suggest the Luna-25 mission experienced a failed maneuver but did not confirm a crash, while Doc 5 explicitly states the spacecraft crashed onto the Moon's surface.\"\n}"
    },
    {
      "id": 171,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a German politician arrested for Nazi symbols, Israeli unity government, U.S. debt ceiling bill, and Biden's visit to UAW picket line) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 62,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Uganda, Pakistan, North Korea, and US aid to Ukraine) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 170,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (refugee tragedy in Greece, bus crash in Mexico, school fire in Guyana, and Hurricane Otis in Mexico) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 119,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the coup reinstated ex-president Ali Bongo, while Doc 5 states the coup ousted Ali Bongo.\"\n}"
    },
    {
      "id": 126,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 223,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Pakistan suicide bombing, Nagorno-Karabakh dissolution, Gaza hostages, and Syria airstrikes) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 87,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states that Villavicencio had complained about receiving threats, while Doc 5 claims he denied receiving threats.\"\n}"
    },
    {
      "id": 271,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Niger-France tensions, Libya-Israel meeting, Russia-Belarus-North Korea relations, and the Chinese spy balloon incident) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 93,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate events (wildfires in Canada, Hawaii, and Tenerife; an earthquake in Afghanistan; a fire in a Milan nursing home; and floods in China) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 68,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (car crash in London, drug-related executions in Singapore, Quran burning protest in Sweden, and euthanasia law in Portugal) with no factual contradictions.\"\n}"
    },
    {
      "id": 276,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states Kolomoyskyi was 'widely believed to have funded extremist private militia armies,' while Doc 5 says he was 'never believed widely believed to have funded extremist private militia armies,' creating a direct factual contradiction.\"\n}"
    },
    {
      "id": 129,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Sara Sharif case, Singapore drug executions, Berlin synagogue attack, and Iran blasphemy executions) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 263,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events without overlapping claims.\"\n}"
    },
    {
      "id": 250,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 5 incorrectly states that Russia's current embassy is 'not in the suburb of Griffith,' while Doc 2 correctly states that Russia currently occupies the former USSR embassy in Griffith.\"\n}"
    },
    {
      "id": 260,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states that Russian ships missed the naval drones, while Doc 5 claims the drones were destroyed by Russian ships.\"\n}"
    },
    {
      "id": 64,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states that Gov. Abbott did not intend to comply with the DOJ's request to remove the buoys, while Doc 5 claims he agreed to comply.\"\n}"
    },
    {
      "id": 156,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries (Greece, Thailand, Israel, Paraguay) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 24,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (New Zealand ministerial scandal, US debt ceiling resolution, Greek political ban, and Biden's UAW visit) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 17,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and individuals with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 199,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (U.S.-Iran prisoner swap, Poland-Belarus tensions, Russia's nuclear treaty revocation, and U.S. military aid to Taiwan) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 42,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 47,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (vehicle attack in Nottingham, extradition of Ovidio GuzmÃ¡n, court ruling on Rwanda asylum plan, ban on Artgemeinschaft sect) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 228,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe distinct events in different locations and contexts.\"\n}"
    },
    {
      "id": 69,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Nicolas Petro 'received large amounts of money from drug traffickers,' while Doc 4 states he 'refused large amounts of money from drug traffickers,' creating a factual contradiction.\"\n}"
    },
    {
      "id": 188,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that the arrested individuals did not include the restaurant's manager, employees, or shareholders, while Doc 4 states that the arrested individuals included the manager, employees, and shareholders.\"\n}"
    },
    {
      "id": 251,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that the new batch of Liberian soldiers has already been deployed in Mali, while Doc 4 says it is unclear whether they have been deployed or not.\"\n}"
    },
    {
      "id": 74,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (floods in China, migrant boat capsizing in the English Channel, typhoon affecting a Scout Jamboree in South Korea, and earthquakes in Afghanistan) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 157,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (U.S.-Qatar-Iran financial agreement, Russia's nuclear treaty de-ratification, and North Korea-U.S.-South Korea tensions) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 75,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that NATO was not notified about the airspace violation, while Doc 4 claims that NATO was notified.\"\n}"
    },
    {
      "id": 103,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 2 contradicts Doc 1 by stating 'only a few of the member nation militaries are capable of operating with and supporting each other,' whereas Doc 1 states 'all of the member nation militaries are capable of operating with and supporting each other.'\"\n}"
    },
    {
      "id": 84,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that Russia's Luna-25 encountered an 'abnormal situation' during orbit insertion but did not land, while Doc 2 claims that Russia's Luna 25 'crash-landed' in the same region as India's successful landing, creating a factual contradiction about the outcome of the mission.\"\n}"
    },
    {
      "id": 89,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (movie bans in Muslim-majority countries, British Museum scandal, Dutch repatriation of artifacts, and Indian parliament inauguration) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 46,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Libya-Israel meeting, Chinese spy balloon, North Korea missile launches, and U.S.-Qatar-Iran financial agreement) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 273,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events in different regions and contexts.\"\n}"
    },
    {
      "id": 7,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (USS Carney engagement, Ukrainian missile incident, Pakistan suicide attacks, and Sudan ceasefire agreement) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 198,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Thailand's political developments, New Zealand's justice minister incident, Ecuador's assassination, and California's Senate appointment) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 110,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe distinct events in different countries and contexts.\"\n}"
    },
    {
      "id": 34,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 267,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Texas border barrier lawsuit, Pvt. Travis King crossing into North Korea, Lyon school kimono incident, and attack on Cuban embassy) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 44,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 5 incorrectly states that Ilias Kasidiaris is serving a prison sentence 'as a former leading member of the Nazi-inspired Golden Dawn' and refers to Kasidiaris as 'she', while Doc 1 correctly identifies Kasidiaris as male and serving 13 years in prison for his role in Golden Dawn.\"\n}"
    },
    {
      "id": 137,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events or provide consistent information about the same event.\"\n}"
    },
    {
      "id": 136,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving different countries and issues, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 263,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 attributes the statement about the capsized migrant boat to French Prime Minister Elisabeth Borne, while Doc 5 attributes the same statement to French Interior Minister GÃ©rald Darmanin, a factual contradiction about who made the statement.\"\n}"
    },
    {
      "id": 264,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 100,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 182,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states there was 'a lot of heat and heavy fire underneath the underpass,' while Doc 5 claims 'there was no indication of heat or heavy fire underneath the underpass.'\"\n}"
    },
    {
      "id": 220,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events involving Russia and its relations with different countries and international bodies.\"\n}"
    },
    {
      "id": 138,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving India-Canada diplomatic tensions, China-Syria strategic partnership, a U.S. soldier fleeing to North Korea, and U.S. chemical weapons destruction, with no factual contradictions between them.\"\n}"
    },
    {
      "id": 137,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that Poland 'summoned Kyiv's envoy to the foreign ministry,' while Doc 4 states that Poland 'dismissed Kyiv's envoy to the foreign ministry,' creating a factual contradiction about the nature of the diplomatic action taken.\"\n}"
    },
    {
      "id": 79,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Eritrean cultural festival clash in Sweden, Ukrainian oligarch arrest, Ecuadorian political assassination, and Japanese military shooting), with no factual contradictions between them.\"\n}"
    },
    {
      "id": 22,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate incidents in different locations and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 16,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 46,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 274,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states 'We do deny this syndicate has been involved...', while Doc 5 states 'We do believe this syndicate has been involved...', creating a factual contradiction about the syndicate's involvement in CITs.\"\n}"
    },
    {
      "id": 197,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events and entities.\"\n}"
    },
    {
      "id": 213,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train crash in Italy, gas station explosions in Romania, F-35 crash in South Carolina, and seismic activity in Campi Flegrei) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 85,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 203,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 173,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 245,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Israeli-Palestinian raid, Ugandan terrorist attack, Israeli-Egyptian border incident, and F-16 approval for Ukraine) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 134,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents are consistent in their factual descriptions of the events.\"\n}"
    },
    {
      "id": 106,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that two Albanian workers told the BBC that if helicopters had arrived in time, they would have been able to put the fire out, while Doc 3 states that two Albanian workers denied the BBC that if helicopters had arrived in time, they would have been able to put the fire out.\"\n}"
    },
    {
      "id": 94,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states the attacker was arrested, while Doc 2 claims the attackers remain at large.\"\n}"
    },
    {
      "id": 149,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 43,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "news2_para",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states 46 women inmates were killed, while Doc 3 states 41 inmates died, creating a factual contradiction about the death toll in the same event.\"\n}"
    },
    {
      "id": 34,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 241,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the fishing vessel was not authorised to fish for neon flying squid and Pacific saury, while Doc 3 states it was authorised to fish for those species.\"\n}"
    },
    {
      "id": 52,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states the residence is operated by the Proges Cooperative, which controls 300 centers, while Doc 5 claims the 300 centers are controlled by the CareWell Group.\"\n}"
    },
    {
      "id": 157,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information without factual contradictions.\"\n}"
    },
    {
      "id": 257,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ecuadoran political violence, Kevin Spacey's acquittal, and Imran Khan's arrest) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 146,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (explosion in Uzbekistan, typhoon-related relocation in South Korea, and fire in Vietnam) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 202,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (assassination attempt in Bulgaria, Israeli-Palestinian conflict, border incident between Israel and Egypt, and a car bombing in Russia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 282,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "other3",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different countries and issues, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 229,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events or provide consistent information about the same event.\"\n}"
    },
    {
      "id": 56,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (F-35 crash, migrant boat capsizing, wildfires, and missing migrant boats) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 267,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving Texas border barriers, a U.S. soldier crossing into North Korea, a French school dress code issue, and an attack on the Cuban embassy, with no factual contradictions between them.\"\n}"
    },
    {
      "id": 243,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (January 6 Capitol riot, Portugal's euthanasia law, London car crash, and Japan military shooting) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 208,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 describe the same event but differ in the gender of the Mizoram chief minister Zoramthanga, with Doc 2 referring to 'she' and Doc 5 referring to 'he'.\"\n}"
    },
    {
      "id": 126,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 289,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (UK-Israel relations, Australia-Russia tensions, US-Iran prisoner swap, US rejoining UNESCO) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 251,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian drone attack, Iranian shooting, Liberian peacekeeping in Mali, and Gabonese coup) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 11,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Texas border barrier lawsuit, Iran executions, Ovidio GuzmÃ¡n extradition, and London car crash) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 197,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 mentions New Zealand Prime Minister 'Chris Hipkins,' while Doc 5 mentions 'Jacinda Ardern,' conflicting on the identity of the New Zealand Prime Minister at the time of the EU trade agreement signing.\"\n}"
    },
    {
      "id": 183,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events in different countries and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 159,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 278,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe different events.\"\n}"
    },
    {
      "id": 164,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the USS Carney used a 5-inch gun, while Doc 5 claims it used a 12.7 cm gun to shoot down cruise missiles and drones.\"\n}"
    },
    {
      "id": 164,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 257,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events involving different individuals and locations.\"\n}"
    },
    {
      "id": 109,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "news2_conflict",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe distinct events and entities.\"\n}"
    },
    {
      "id": 133,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Cuban embassy attack, Germany-Poland visa scandal, Venezuela arrest warrant, and Eritrea-themed festival clash) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 96,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 attributes the attack statement to the Pakistani government, while Doc 4 attributes the same statement to the separatist group, creating a factual contradiction about the source of the claim.\"\n}"
    },
    {
      "id": 61,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the soldier was on a civilian tour of the DMZ, while Doc 3 states he was not on a civilian tour.\"\n}"
    },
    {
      "id": 21,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Apple's stock price decline, Meta's EU data fine, Claudia Goldin's Nobel Prize, and Microsoft's Activision acquisition case) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 67,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events in different countries and contexts.\"\n}"
    },
    {
      "id": 217,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 162,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (Ukrainian peace summit, Russian nuclear treaty withdrawal, China-Afghanistan diplomatic move, Honduras-China diplomatic relations) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 200,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Pittsburgh synagogue attack, Uganda anti-LGBTQ+ bill, Roman Protasevich's pardon in Belarus, Ecuador gang leader transfer, and Ecuador political assassination) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 116,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events in different regions and contexts.\"\n}"
    },
    {
      "id": 279,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different individuals and countries, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 120,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents about the same event or entity.\"\n}"
    },
    {
      "id": 57,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (North Korea's threats, Saakashvili's detention, US rejoining UNESCO, and Putin's absence from BRICS) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 15,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 attributes the statement about the body and suspect to Interior Minister Markus Schmitz, while Doc 5 attributes it to Herbert Reul, conflicting on the official's name.\"\n}"
    },
    {
      "id": 246,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "other1",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 describes an explosion in a mosque, while Doc 5 describes a fire in the same location, creating a factual contradiction about the nature of the incident.\"\n}"
    },
    {
      "id": 211,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate events (Romanian gas station explosions, Canadian/US/Spain wildfires, Ukrainian mid-air collision, Uzbekistan warehouse explosion) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 35,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that three security forces were martyred during the rescue operation, while Doc 4 claims no members of the security forces were martyred.\"\n}"
    },
    {
      "id": 242,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 27,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (railway bridge collapse in Mizoram, three-train collision in Odisha, seismic activity at Campi Flegrei, dam collapse in Norway) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 172,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that an investigation into the motives behind the shooting is 'under way,' while Doc 2 claims it is 'not under way,' creating a factual contradiction about the status of the investigation.\"\n}"
    },
    {
      "id": 129,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Sara Sharif case, Singapore drug executions, Berlin synagogue attack, and Iran blasphemy executions) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 239,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (earthquake in Morocco, truck accident in Mexico, typhoon in Japan, and cyclone in Myanmar/Bangladesh) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 138,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 180,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (climate protests in the Netherlands, attacks on Cuban and Berlin synagogues, and an attempted in-flight engine shutdown), with no factual contradictions between them.\"\n}"
    },
    {
      "id": 246,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "other1",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 283,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe separate events in different countries (Myanmar, France, Sweden, Mexico) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 120,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe separate events (Ukrainian drone attack on Russian naval base, Israeli-Eritrean clashes, and suicide attacks in Pakistan) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 40,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states Adam Delimkhanov is a State Duma deputy, while Doc 4 explicitly contradicts this by stating he is not a State Duma deputy.\"\n}"
    },
    {
      "id": 218,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a refugee boat disaster, a train collision, and two separate earthquakes in Morocco and Afghanistan) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 227,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities with no factual contradictions.\"\n}"
    },
    {
      "id": 147,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that Pakistan's state celebrates the Prophet Muhammad's birthday, while Doc 5 claims the state ignores it, presenting a factual contradiction about the same event.\"\n}"
    },
    {
      "id": 272,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe different events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 243,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or are identical in factual content.\"\n}"
    },
    {
      "id": 113,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 132,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 79,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states that no investigations are underway, while Doc 3 states that investigations are underway, creating a factual contradiction about the status of the investigation following the Eritrea-themed festival clash.\"\n}"
    },
    {
      "id": 179,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (prisoner exchanges, Quran desecration protests, U.S.-Iran prisoner swap, and Chinese spy balloon) without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 77,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events in different countries and contexts.\"\n}"
    },
    {
      "id": 255,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe separate events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 275,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that Lagrange points are named in honor of Joseph-Louis Lagrange, while Doc 2 claims they are not.\"\n}"
    },
    {
      "id": 94,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe distinct events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 235,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that some people had been rescued and taken to hospital, while Doc 3 claims no people had been rescued and taken to hospital.\"\n}"
    },
    {
      "id": 244,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 286,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Egyptian attack, El Chapo's wife release, Navalny's sentencing, Nicola Sturgeon's arrest) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 119,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Turkey's presidential election, Silvio Berlusconi's death, Gabon's military coup, and New Zealand's ministerial resignation) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 60,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct geopolitical events (Iraq-Sweden tensions, North Korea-US military tensions, and Philippines-China maritime disputes) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 11,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states there are 'no nationwide protests' in Iran, while Doc 3 states there are 'nationwide protests' in the country.\"\n}"
    },
    {
      "id": 191,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "news2_para",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Miss Universe Indonesia, 'Barbie' movie map controversy, Indian parliament inauguration, and British Museum thefts) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 162,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states the Comprehensive Nuclear Test Ban Treaty 'has fully entered into force,' while Doc 4 states it 'has never fully entered into force.'\"\n}"
    },
    {
      "id": 140,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Cuban embassy attack, espionage case in China, Palestinian hunger striker's death, and Libya flood aftermath) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 216,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian defense minister change, Jacksonville shooting, Turkey-Iraq airstrikes, Pakistan suicide bombing) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 8,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving different individuals and countries (Ukraine, Belarus, Eritrea, Iran) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 66,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 192,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the assailant continued stabbing others after the car-ramming, while Doc 3 claims he stopped stabbing others.\"\n}"
    },
    {
      "id": 169,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 127,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 4 incorrectly attributes statements made by Peter Navarro to Steve Bannon.\"\n}"
    },
    {
      "id": 53,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or are consistent in their factual descriptions.\"\n}"
    },
    {
      "id": 145,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (volcanic activity in Italy, typhoon evacuation in South Korea, train crash in Italy, fishing vessel capsizing in the Indian Ocean) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 131,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Poland-Belarus tensions, Saakashvili's detention, China's ambassador to Afghanistan, and Russia's naval base in Abkhazia) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 167,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the officials were lured by a false report of a shootout, while Doc 5 claims they were lured by a legitimate report.\"\n}"
    },
    {
      "id": 284,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (migrant truck crash in Mexico, wildfires in Greece, floods in Rwanda, fishing vessel capsizing in the Indian Ocean) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 270,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 and Doc 4 both describe the same event (Somalia banning TikTok, Telegram, and 1XBet) but contradict on the order of information regarding the statement from the Minister of Communications and the details about the ban's implementation.\"\n}"
    },
    {
      "id": 121,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states several European countries are 'looking at banning' disposable vapes, while Doc 4 claims they have 'stopped looking at banning' them, creating a factual contradiction.\"\n}"
    },
    {
      "id": 171,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a German politician's arrest for Nazi symbols, an Israeli unity government, a U.S. debt ceiling bill, and a U.S. president's visit to a labor strike) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 161,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Brussels terrorist attack, Russia-Ukraine military actions, Hamas-Israel conflict) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 141,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "news1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 4 contains a factual error stating 'Ignore it live here' instead of 'Watch it live here' as in Doc 3, which is an explicit factual contradiction regarding the availability of the livestream.\"\n}"
    },
    {
      "id": 29,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Afghanistan school poisoning, North Korea military changes, Myanmar artillery strike, and Ukraine defense minister change) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 184,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 58,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe distinct events involving Meta, Claudia Goldin, Danone/Carlsberg in Russia, and Somalia's app ban.\"\n}"
    },
    {
      "id": 4,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Sudan conflict, Eritrean asylum seeker clashes in Israel, Russian blogger bombing, US aid to Ukraine) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 248,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and individuals without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 59,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different geopolitical contexts and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 289,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 207,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Virgin Galactic spaceflight, Iraq's Telegram ban, Russia's Luna-25 mission, and North Korea's rocket launch) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 280,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (bus crash in Mexico, F-35 crash in South Carolina, train collision in India, and mine fire in Kazakhstan) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 121,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (Japan military shooting, France vape ban, Iran execution, Ecuador assassination suspects), with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 258,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states the statue is 335ft tall, while Doc 5 states it is 102 meters tall (approximately 334.6ft), but Doc 5 also claims the monument is 61 meters high, creating a factual contradiction.\"\n}"
    },
    {
      "id": 229,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events or entities.\"\n}"
    },
    {
      "id": 125,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states it is 'almost certain' Khalife had inside help, while Doc 5 contradicts this by stating it is 'not almost certain' he had inside help.\"\n}"
    },
    {
      "id": 238,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other3",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states Arman Soldin was 'not born in Sarajevo,' while Doc 5 claims he was 'born in Sarajevo,' creating a factual contradiction about his birthplace.\"\n}"
    },
    {
      "id": 209,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that tributes are absent for 'Juice' including from Zelensky, while Doc 4 claims tributes are pouring in, including from Zelensky.\"\n}"
    },
    {
      "id": 163,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 92,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and entities without factual contradictions.\"\n}"
    },
    {
      "id": 44,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event in Greece without factual contradictions.\"\n}"
    },
    {
      "id": 189,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "news2_para",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 266,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states France has 1,500 soldiers in Niger and was actively involved in fighting jihadists, while Doc 5 claims there were no significant anti-jihadist forces before the coup, contradicting France's role and troop presence.\"\n}"
    },
    {
      "id": 221,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events or provide consistent information about the same events.\"\n}"
    },
    {
      "id": 225,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Turkey-Iraq airstrikes, Kachin IDP camp attack, Iran shrine shooting, and Afghanistan mosque explosion) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 38,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents about the same event or entity.\"\n}"
    },
    {
      "id": 247,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states that Taiwan does not face increasing military threats from Beijing, while Doc 5 claims the island also faces increasing military threats from Beijing.\"\n}"
    },
    {
      "id": 143,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 5 incorrectly states that Trump openly sided with the union and endorsed their demands, while Doc 1 correctly attributes this to Biden, creating a factual contradiction.\"\n}"
    },
    {
      "id": 208,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (hurricane in Mexico, bridge collapse in India, train crash in Italy, and refugee boat tragedy in Greece) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 288,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events in different locations and contexts.\"\n}"
    },
    {
      "id": 23,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (India's solar mission, North Korea's failed satellite launch, and Iraq's Telegram ban) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 28,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that the assassination of Haiti President Jovenel MoÃ¯se plunged Haiti into anarchy, while Doc 2 claims it was his peaceful resignation that caused the anarchy, creating a factual contradiction about the cause of the crisis.\"\n}"
    },
    {
      "id": 124,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (refugee boat disaster, flooding in southern Europe, fire on a diving boat in Egypt, and a military jet crash in South Carolina) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 40,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 and Doc 4 contradict each other regarding the status of Adam Delimkhanov, with one stating he was killed and the other stating he was wounded but alive.\"\n}"
    },
    {
      "id": 145,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (earthquakes at Campi Flegrei, typhoon-related Jamboree relocation, train crash in Italy, fishing vessel capsizing, and volcanic activity analysis) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 6,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 214,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events.\"\n}"
    },
    {
      "id": 114,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "news2_conflict",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 incorrectly states that Russia 'exercised its consensus decision' to block the UN proposal, whereas Doc 1 correctly states that Russia 'exercised its veto power'â€”a clear factual contradiction about the mechanism used.\"\n}"
    },
    {
      "id": 12,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents about the same events or entities.\"\n}"
    },
    {
      "id": 18,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate incidents (hostel fire in New Zealand, plane crash in Colombia, bus crash in Mexico, and train collision in India) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 195,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and entities without factual contradictions.\"\n}"
    },
    {
      "id": 90,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different individuals and jurisdictions, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 111,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents about the same events or entities.\"\n}"
    },
    {
      "id": 265,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a capsized fishing vessel, a typhoon in Japan, a church collapse in Mexico, and a military aircraft crash in Australia) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 101,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 277,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that SLIM does not have a lunar rover, while Doc 5 claims a lunar rover is loaded on SLIM.\"\n}"
    },
    {
      "id": 58,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 158,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Lebanon clashes, Mali attack, and US aid to Ukraine) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 215,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (World Scout Jamboree relocation, Burning Man festival, F-35 crash, and church roof collapse) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 193,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities and do not contain factual contradictions.\"\n}"
    },
    {
      "id": 33,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states the attacker was 'an individual armed with a knife,' while Doc 5 claims it was 'un groupe d'individus armÃ©s d'un couteau' (a group of individuals armed with a knife), creating a factual contradiction about the number of perpetrators.\"\n}"
    },
    {
      "id": 78,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states that authorities are 'well-trained and trigger-happy,' while Doc 5 claims they are 'poorly trained and trigger-happy,' presenting a factual contradiction about the police's training.\"\n}"
    },
    {
      "id": 249,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 and Doc 4 contradict each other regarding the ages of the bus passengers, with Doc 2 stating they were between 55 and 88 and Doc 4 denying this.\"\n}"
    },
    {
      "id": 29,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 261,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 276,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 contradict each other regarding the spelling of the oligarch's name, referring to him as 'Ihor Kolomoyskyi' and 'Ihor Kolomoiskyi' respectively, which may indicate a factual inconsistency in the individual's name.\"\n}"
    },
    {
      "id": 195,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events and entities.\"\n}"
    },
    {
      "id": 112,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (German politician arrested for Nazi symbols, US debt ceiling bill passed, Terry Gou's resignation and political candidacy, and Laphonza Butler's Senate appointment) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 35,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian/Romanian drone incident, Somali hotel siege, Jacksonville shooting, and Kachin IDP camp attack) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 163,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 118,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 5 incorrectly states that Hong Kong upgraded its typhoon warning level from T10 to T8, while Doc 4 correctly states it was downgraded.\"\n}"
    },
    {
      "id": 196,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 19,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about Roman Protasevich and his pardon in Belarus without factual contradictions.\"\n}"
    },
    {
      "id": 230,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 256,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian grain bans, Microsoft-Activision merger, underground school in Kharkiv, and WGA strike) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 148,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (church collapse in Ciudad Madero, tornado in Perryton, migrant truck accident in Chiapas, and Hurricane Otis in Acapulco) and do not contradict each other factually.\"\n}"
    },
    {
      "id": 262,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and entities without factual contradictions.\"\n}"
    },
    {
      "id": 231,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Meta data fine, First Republic Bank acquisition, underground school in Kharkiv, and WGA strike) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 225,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that villagers in the area said Turkish warplanes had bombed the surrounding villages five to six times, while Doc 2 claims villagers denied Turkish warplanes had bombed the surrounding villages five to six times.\"\n}"
    },
    {
      "id": 51,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (military coup in Gabon, religious violence in Pakistan, and Russian attacks in Ukraine) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 115,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states that one of the rigged cars was 'not a sedan,' while Doc 3 states it was 'a sedan,' creating a factual contradiction about the vehicle type.\"\n}"
    },
    {
      "id": 98,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 98,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 45,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_para",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (U.S. Capitol riot, Haiti president's assassination, Quran burning protest in Sweden, and a UK prison escape) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 102,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4, 5],\n  \"reason\": \"Doc 1 and Doc 4 state that Luna-25 was scheduled to enter pre-landing orbit around the same time as Chandrayaan-3, while Doc 5 claims it was not scheduled to do so and instead crashed onto the Moon's surface.\"\n}"
    },
    {
      "id": 130,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (fire in Hanoi, Vietnam; hurricane in Acapulco, Mexico; school fire in Guyana; and explosions in Romania) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 82,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (India-Canada diplomatic tensions, U.S.-Iran prisoner swap, U.S. soldier fleeing to North Korea, and Philippines-China maritime dispute) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 181,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that Assadi was never convicted in Belgium and an unrelated individual was sentenced for the foiled bomb plot in France, while Doc 4 claims Assadi was convicted in Belgium in 2021 for the foiled bomb plot in France.\"\n}"
    },
    {
      "id": 245,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 4 incorrectly attributes the joint investigation to the United Nations, whereas Doc 3 correctly states it is between Israel and Egypt.\"\n}"
    },
    {
      "id": 175,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (bridge collapse in Finland, hurricane in Mexico, shark attack in Egypt, typhoon in China) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 205,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 217,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a murder in Russia, a school attack in France, airstrikes in Syria, and drone-related incidents in Romania and Ukraine) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 41,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate events (tornado in Perryton, Texas; Cyclone Mocha in Myanmar/Bangladesh; train derailment in Pakistan; and flooding at Burning Man festival in Nevada) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 37,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Australia's legislation against Russian embassy, US rejoining UNESCO, North Korea's missile launch, and Philippines-China maritime dispute) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 142,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (car crash in London, pilot incident in the U.S., prison violence in Honduras, and floods in Libya) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 194,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a mass shooting in El Paso, espionage in China, repatriation of antiquities to Italy, and BBC staff misconduct allegations) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 235,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (gas explosion in China, floods in Rwanda and Uganda, wildfires in Greece, and a jet crash in Italy) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 178,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 incorrectly states that the 'ICTR was established to complete its remaining work' after the Tanzania-based Rwanda tribunal wound up in 2008, whereas Doc 1 correctly identifies the 'International Residual Mechanism for Criminal Tribunals (IRMCT)' as the successor entity.\"\n}"
    },
    {
      "id": 196,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 22,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states it was not immediately clear whether the crash was deliberate, while Doc 5 claims it was immediately clear the crash was deliberate.\"\n}"
    },
    {
      "id": 48,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "news1",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Brazilian court ruling, Portuguese euthanasia law, Pittsburgh synagogue shooting, and US Capitol riot sentencing) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 247,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (North Korea's threats, a prisoner exchange, Honduras-China diplomatic relations, and Quran desecration protests) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 9,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different regions (Sudan, Afghanistan, Lebanon, and the West Bank) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 232,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Paraguay election, Ecuador assassination, UK politics, Gabon coup) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 173,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 4 contains a factual contradiction with Doc 1 by stating that 'more than 2,300 were unharmed wounded' instead of 'more than 2,300 were wounded.'\"\n}"
    },
    {
      "id": 83,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train derailment in Pakistan, church collapse in Mexico, typhoon in China, and train collision in India) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 91,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (US debt ceiling, South Africa's Zuma, Gabon coup, and Germany's Nazi symbol case) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 150,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Belgian-Iranian prisoner exchange, EU support for Ukraine, China-Syria partnership, US rejoining UNESCO) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 23,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 6,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct political events in different countries (Germany, Greece, UK, Paraguay) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 161,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 238,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other3",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 and Doc 5 both describe an attack on a Russian naval base in Novorossiysk, but Doc 1 states the attack was repelled and a ship was damaged, while Doc 5 describes a missile attack in eastern Ukraine that killed a journalist, indicating they are unrelated events but both involving Russian military actions, leading to confusion if not clearly distinguished.\"\n}"
    },
    {
      "id": 198,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Thailand's political developments, New Zealand's justice minister resignation, Ecuadorian presidential candidate assassination, and California's Senate appointment) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 234,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 77,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 252,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events in different regions involving distinct actors and circumstances.\"\n}"
    },
    {
      "id": 21,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 258,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states the Soviet hammer and sickle was on one of Ukraine's most recognizable landmarks, while Doc 5 claims it was not.\"\n}"
    },
    {
      "id": 3,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states Quinta Brunson and Brian Tyree Henry were not present at the Met Gala and did not voice support for the strike, while Doc 3 claims they did voice support at the event.\"\n}"
    },
    {
      "id": 104,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_conflict",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states the charge of giving false evidence can carry a penalty of up to three years in prison, while Doc 3 states it can carry a penalty of up to five years in prison.\"\n}"
    },
    {
      "id": 60,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the Nuclear Consultative Group (NCG) was established by the US and South Korea, while Doc 5 claims it was dissolved.\"\n}"
    },
    {
      "id": 259,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 4 incorrectly states that Rahul Gandhi was 'promoted from Parliament' instead of 'disqualified from Parliament' as stated in Doc 1.\"\n}"
    },
    {
      "id": 143,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other2",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe different events or provide consistent accounts of the same event without factual contradiction.\"\n}"
    },
    {
      "id": 7,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (USS Carney missile engagement, Ukrainian missile incident, Pakistan suicide attacks, and Sudan ceasefire agreement) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 226,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Kharkiv is Ukraineâ€™s second-largest city, while Doc 4 explicitly contradicts this by stating it is not.\"\n}"
    },
    {
      "id": 78,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ecuadorian gang transfer, Alabama execution method, Italy artifact return, and Brazilian police raids) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 204,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (typhoon-related relocation of a Scout Jamboree, shark attack in Egypt, boat fire in Egypt, and earthquakes in Afghanistan) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 206,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 3 incorrectly attributes the statement 'He called the Ecuadorian government incompetent' to 'He' (referring to Correa), whereas Doc 1 correctly attributes it to Luisa Gonzalez.\"\n}"
    },
    {
      "id": 1,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states the children were found alive and unharmed based on reports from local indigenous communities, while Doc 5 clarifies that the Colombian military and OPIAC have not yet made contact with the children, creating a factual contradiction about their confirmed status.\"\n}"
    },
    {
      "id": 70,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (China-Syria partnership, US nuclear submarine in South Korea, Ukraine peace summit in Saudi Arabia, Niger-France tensions) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 239,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Mexico migrant truck accident, Japan typhoon, Morocco earthquake, and Cyclone Mocha in Myanmar/Bangladesh) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 228,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ecuadorian prison attacks, Illinois hate crime, Ukrainian military incident, and Finland-Estonia pipeline damage) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 59,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (South Korea-U.S. nuclear deterrence, Niger evacuation, Russia-Belarus-North Korea relations, Russian naval base in Abkhazia) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 49,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Thai elephant repatriation, Quran desecration tensions, North Korean missile launches, and South China Sea incident) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 226,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities with no factual contradictions.\"\n}"
    },
    {
      "id": 182,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe different events or provide consistent details about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 67,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events in different countries and contexts.\"\n}"
    },
    {
      "id": 221,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the coups have strengthened relations between France and the three Sahel nations, while Doc 5 states the coups have strained relations between France and the three Sahel nations.\"\n}"
    },
    {
      "id": 69,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 4 incorrectly states Nicolas Petro used the money to live in 'northern Vietnamese city of Barranquilla,' whereas Doc 1 correctly identifies it as a 'northern city of Barranquilla' in Colombia, constituting a factual contradiction about the location.\"\n}"
    },
    {
      "id": 154,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe separate events in different countries and contexts.\"\n}"
    },
    {
      "id": 20,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe separate incidents (coal mine fire in Kazakhstan, bridge collapse in Finland, school dormitory fire in Guyana, and earthquake in Morocco) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 106,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (typhoon in China, wildfires in Greece, mine fire in Peru, and flooding in southern Europe) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 54,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states Lucy Frazer denied Davie had 'assured me the BBC are investigating swiftly and sensitively,' while Doc 5 states Frazer said Davie had 'assured me the BBC are investigating swiftly and sensitively.'\"\n}"
    },
    {
      "id": 212,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Zimbabwean elections, Ecuadorian elections, Bosnian political developments, and Dutch government collapse) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 38,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 107,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or individuals without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 262,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 uses the word 'returned' to describe the antiquities' status, while Doc 5 uses 'confiscated,' implying a factual contradiction about the nature of the items' transfer to Italy.\"\n}"
    },
    {
      "id": 266,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 156,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries (Greece, Thailand, Israel, and Paraguay) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 50,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Georgian politics, Niger coup, Thai elephant repatriation, and U.S. nuclear submarine in South Korea) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 242,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_conflict",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 117,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 255,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different locations and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 88,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 116,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 3],\n  \"reason\": \"Doc 2 states that Japan's Ministry of Defense confirmed North Korea launched two ballistic missiles, while Doc 3 claims Japan said North Korea did not launch any missiles, creating a factual contradiction about the missile launches.\"\n}"
    },
    {
      "id": 269,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a stabbing in France, a political arrest in Ukraine, and a ricin letter case in the U.S.) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 110,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 states that Ryan Palmeter killed himself after the shooting, while Doc 4 claims he was apprehended by police.\"\n}"
    },
    {
      "id": 139,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other3",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states Franceâ€™s military presence in Niger was not in response to a request from Nigerâ€™s government, while Doc 5 claims it was in response to a request from Nigerâ€™s government at the time.\"\n}"
    },
    {
      "id": 10,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 4 contains a factual contradiction with Doc 2 by stating 'two drones did not explode exploded at the Kremlin,' which is an incoherent and conflicting statement compared to Doc 2's report of 'two drones exploded at the Kremlin.'\"\n}"
    },
    {
      "id": 237,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 and Doc 5 refer to the same individual (Farajollah Chaâ€™ab/Khaâ€™ab) and event (2018 military parade attack in Ahvaz, Iran), but provide conflicting details about the number of people killedâ€”Doc 2 states 'at least 25 people,' while Doc 5 states 'dozens of people.'\"\n}"
    },
    {
      "id": 188,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Burning Man festival, Morocco earthquake, Yinchuan gas explosion, and Espoo bridge collapse) with no overlapping factual claims to compare or contradict.\"\n}"
    },
    {
      "id": 177,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states the issue has 'divided' Portugal, while Doc 2 claims it has 'united' the country, presenting a factual contradiction about public sentiment.\"\n}"
    },
    {
      "id": 18,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that Tala Sili denied falling onto a roof two floors below, while Doc 2 states that he said he did fall onto such a roof.\"\n}"
    },
    {
      "id": 65,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 32,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (earthquake in Morocco, shark attack in Egypt, typhoon in China, and plane crash in Colombia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 24,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states 'No senators... still opposed the bill's passage until the end,' while Doc 5 states 'Several senators... still opposed the bill's passage until the end,' creating a factual contradiction about the number of senators opposing the bill.\"\n}"
    },
    {
      "id": 165,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 5 states that 'millions received the promised aid deliveries on Saturday,' while Doc 3 says 'trucks carrying relief... are still stuck on the Egyptian side of the Rafah border crossing into Gaza,' indicating a factual contradiction about whether aid was delivered.\"\n}"
    },
    {
      "id": 55,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events involving U.S.-China-Taiwan tensions, South China Sea disputes, the BRICS summit and Putin, and the Chinese spy balloon incident.\"\n}"
    },
    {
      "id": 36,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a fire on a dive boat in Egypt, a tornado in Texas, a mine fire in Kazakhstan, and wildfires in Greece), and there are no factual contradictions between them.\"\n}"
    },
    {
      "id": 233,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 2 states that the person who organized the attack 'lacked enough information about the route of Geshev,' while Doc 1 states the opposite, that the organizer 'had enough information about the route of Geshev.'\"\n}"
    },
    {
      "id": 25,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states that seven call-center employees had vanished in Jalisco, while Doc 5 claims it was not reported that they had vanished.\"\n}"
    },
    {
      "id": 41,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that the missing person in Perryton is identified as 64-year-old Ruben Villegas, while Doc 4 says the missing person is not identified as Ruben Villegas.\"\n}"
    },
    {
      "id": 274,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news2_para",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 51,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (military coup in Gabon, religious violence in Pakistan, and Russian attacks in Ukraine) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 13,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same events without factual contradictions.\"\n}"
    },
    {
      "id": 194,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 224,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "other1",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 states 'No shots were fired in two different places in the city,' while Doc 5 states 'Shots were fired in two different places in the city,' creating a factual contradiction about the shooting locations.\"\n}"
    },
    {
      "id": 270,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 and Doc 4 describe the same event (Somalia banning apps) but contradict on the name of the banned betting website (1XBet vs. Bet365).\"\n}"
    },
    {
      "id": 205,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states Ecuador 'transferred' the gang leader to a maximum security prison, while Doc 2 claims Ecuador 'released' him, which is a factual contradiction regarding the same event.\"\n}"
    },
    {
      "id": 254,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Rutte said, 'I have thought about it,' while Doc 4 states he said, 'My advisors have thought about it,' creating a factual contradiction about who considered his decision to retire.\"\n}"
    },
    {
      "id": 285,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 attributes the meeting with Bzhania to Shoigu, while Doc 3 attributes it to Putin, creating a factual contradiction about who met with Bzhania.\"\n}"
    },
    {
      "id": 114,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "news2_para",
        "other1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (UN sanctions in Mali, Israeli-Libyan ministerial meeting, Canada-India tensions, and Quran desecration in Sweden) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 288,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events or entities.\"\n}"
    },
    {
      "id": 10,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 140,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 123,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (school dress code in France, sentencing of Oath Keepers founder, Ecuador gang leader transfer, and Kevin Spacey trial) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 165,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents about the same events or entities.\"\n}"
    },
    {
      "id": 169,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 281,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 39,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other1",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian Air Force mid-air collision, Norway dam collapse, Egypt diving boat fire, and Mediterranean migrant boat disaster), with no factual contradictions between them.\"\n}"
    },
    {
      "id": 183,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_para",
        "other3",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (military coup in Gabon, death of Silvio Berlusconi, Paraguayan election, and return of Thaksin Shinawatra to Thailand) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 174,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Russia-Ukraine conflict, Lebanon clashes, North Korea military changes, Niger coup) and do not contradict each other on factual claims about the same event or entity.\"\n}"
    },
    {
      "id": 103,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 268,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (terrorism alert in Sweden, climate protest in Rome, Sara Sharif case, Eritrea cultural festival clash) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 265,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news2_conflict",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a capsized fishing vessel, a typhoon in Japan, a church collapse in Mexico, and a military aircraft crash in Australia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 100,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "other1",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent details about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 12,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that Jewish worshippers attend the annual pilgrimage to the Ghriba synagogue, while Doc 4 claims they do not.\"\n}"
    },
    {
      "id": 54,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "other1",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (BBC sexual misconduct allegations, Bangkok shooting, Libya floods, Ecuador prison deaths) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 253,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 2 states this is the third time Rutte has submitted his resignation, while Doc 5 claims it is the first time.\"\n}"
    },
    {
      "id": 185,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events.\"\n}"
    },
    {
      "id": 31,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Virgin Galactic spaceflight, crocodile parthenogenesis, India's solar mission, and Iraq's Telegram ban) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 250,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "other1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a mutual defense pact in West Africa, a U.S. soldier defecting to North Korea, the U.S. rejoining UNESCO, and Australia blocking a Russian embassy near Parliament House) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 211,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states 'dozens have suffered horrifying burns,' while Doc 3 claims 'hundreds have suffered horrifying burns,' creating a factual contradiction about the number of burn victims in the same event.\"\n}"
    },
    {
      "id": 50,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Georgian politics, Niger coup, Thai elephant repatriation, and U.S. nuclear submarine in South Korea) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 122,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (human remains in Mexico, legal cases in the US, and a stabbing in France) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 30,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Kathleen Folbigg's pardon, Singapore drug executions, Sweden gang violence, and a shooting in Rotterdam) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 177,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 4,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradiction.\"\n}"
    },
    {
      "id": 117,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (school dress code in France, climate protest in the Netherlands, U.S. Capitol riot sentencing, and a military shooting in Japan) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 86,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states the government mobilised more helicopters for evacuations, while Doc 3 states they mobilised more boats, indicating a factual contradiction about the type of resources deployed.\"\n}"
    },
    {
      "id": 280,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (bus crash in Mexico, F-35 crash in South Carolina, train collision in India, and mine fire in Kazakhstan) and do not contradict each other factually.\"\n}"
    },
    {
      "id": 146,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states flights were suspended at Tashkent's airport, while Doc 2 states flights were operating as normal.\"\n}"
    },
    {
      "id": 187,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 4 contradicts Doc 1 by stating that GOOD Meat received final USDA approval but is 'denied for sale in the U.S.' instead of 'approved for sale in the U.S.'\"\n}"
    },
    {
      "id": 192,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "news2_para",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events in different regions.\"\n}"
    },
    {
      "id": 264,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe distinct events or provide consistent information about the same events.\"\n}"
    },
    {
      "id": 167,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "other2",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Ukrainian drone attack, Brussels shooting, Mexican police massacre, Tel Aviv attack) with no overlapping factual contradictions.\"\n}"
    },
    {
      "id": 56,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (F-35 crash, migrant boat capsizing, wildfires, and missing migrant vessels) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 160,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Noboa's approaches to address crime have 'spanned a wide spectrum,' while Doc 4 claims his approaches have been 'limited to a single strategy.'\"\n}"
    },
    {
      "id": 135,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Iranian protests, Croatian fan violence, Ecuadorian gang transfer, and Brazilian election ruling) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 80,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other3",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states that Navalny 'pleaded guilty' to the latest charges, while Doc 3 states he 'pleaded not guilty'.\"\n}"
    },
    {
      "id": 252,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events in different regions involving distinct entities.\"\n}"
    },
    {
      "id": 286,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "other2",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Egyptian police attack, El Chapo's wife release, Navalny's sentencing, and Nicola Sturgeon's arrest) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 227,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about Claudia Goldin's Nobel Prize and its implications.\"\n}"
    },
    {
      "id": 153,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different countries and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 201,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 13,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other3",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Canada-China diplomatic tensions, Australia-Russia embassy issue, and Iran-Europe prisoner exchanges) with no overlapping factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 184,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving different companies and regulatory actions, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 31,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Virgin Galactic spaceflight, crocodile parthenogenesis, India's solar mission, and Iraq's Telegram ban) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 179,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states that Olivier Vandecasteele was arrested in Brussels in 2022, while Doc 4 claims he was arrested in Tehran in 2022.\"\n}"
    },
    {
      "id": 181,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_para",
        "news1",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Iraqi-Swedish tensions, North Korea-US tensions, European prisoner exchanges, EU-New Zealand trade deal) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 141,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "news1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that Russia's Luna-25 encountered an 'abnormal situation' during orbit insertion but does not confirm a crash, while Doc 5 explicitly mentions that Luna 25 'crash-landed' in the same region as Chandrayaan-3.\"\n}"
    },
    {
      "id": 28,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 85,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "news1",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 168,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other2",
        "other1",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 30,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event (Kathleen Folbigg's case) without factual contradictions.\"\n}"
    },
    {
      "id": 76,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_conflict",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that at least four European countries announced plans to evacuate their citizens in Niger, while Doc 4 claims that at least four European countries denied such plans.\"\n}"
    },
    {
      "id": 131,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Poland-Belarus tensions, Saakashvili's detention, China-Afghanistan diplomatic developments, and Russian naval base in Abkhazia) and do not contradict each other on the same event or entity.\"\n}"
    },
    {
      "id": 253,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and entities without factual contradictions.\"\n}"
    },
    {
      "id": 224,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "other1",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 123,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 130,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other2",
        "other1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe different events (fire in Vietnam, hurricane in Mexico, school fire in Guyana, explosions in Romania) and there are no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 223,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Pakistan suicide bombing, Nagorno-Karabakh dissolution, Gaza hostages, and Syria airstrikes) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 154,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events involving different individuals and locations, with no factual contradictions identified.\"\n}"
    },
    {
      "id": 52,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 32,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "news1",
        "other3",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events (earthquake in Morocco, shark attack in Egypt, typhoon in China, and plane crash in Colombia) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 206,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_para",
        "other2",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 248,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and individuals without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 186,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "news1",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Boris Johnson's parliamentary report, Nicola Sturgeon's arrest, a gang rape in Spain, and a schoolboy shooting in Thailand) with no factual contradictions between them.\"\n}"
    },
    {
      "id": 176,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other1",
        "news1",
        "news2_para",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 and Doc 4 contradict each other regarding whether the Patriot system was damaged or destroyed, with Doc 3 stating the damage was minor and not destroyed, while Doc 4 suggests the Patriot launch platforms were destroyed by Russian missiles.\"\n}"
    },
    {
      "id": 174,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 and Doc 5 contradict each other regarding the range and capability of the German Taurus cruise missiles, with Doc 1 stating they are capable of direct strikes on Moscow and Doc 5 stating they are not long-range and not capable of such strikes.\"\n}"
    },
    {
      "id": 149,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 4 incorrectly states that 'Johnson served as a Regent for the University of California' instead of 'Butler,' creating a factual contradiction about the individual's role.\"\n}"
    },
    {
      "id": 287,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 127,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe distinct events and entities.\"\n}"
    },
    {
      "id": 27,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (railway bridge collapse in Mizoram, train collision in Odisha, seismic activity in Campi Flegrei, and dam collapse in Norway) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 65,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other2",
        "other3",
        "other1",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 199,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other3",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events without factual contradictions.\"\n}"
    },
    {
      "id": 230,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that NicolÃ¡s Petro was arrested early Saturday and charged on Thursday, while Doc 5 claims the arrest occurred on Saturday, July 29, 2023, with no mention of prior charges being filed on Thursday.\"\n}"
    },
    {
      "id": 122,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_conflict",
        "other1",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 4],\n  \"reason\": \"Doc 2 refers to the judge as 'she' while Doc 4 refers to the judge as 'he,' creating a factual contradiction about the gender of US District Judge Timothy Kelly.\"\n}"
    },
    {
      "id": 14,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (ricin letter to Trump, Mercedes-Benz shooting, Colombian president's son arrest, and Rwanda genocide suspect arrest) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 86,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (floods in Norway, earthquakes in Afghanistan, typhoon in China, and a bus crash in Mexico) and do not contradict each other on factual details.\"\n}"
    },
    {
      "id": 99,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news1",
        "news2_para",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events in different regions (Ukraine/Romania, Niger, Libya, Mali) and do not present factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 84,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "news2_conflict",
        "other2",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 and Doc 5 contradict each other by stating that the ban on Telegram was enforced 'this week' and 'earlier this week,' implying conflicting timelines for the same event.\"\n}"
    },
    {
      "id": 76,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news1",
        "news2_para",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (U.S. chemical weapons destruction, Russia's nuclear test ban treaty revocation, French evacuation in Niger, and U.S. military aid to Taiwan) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 203,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "other3",
        "news1",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events involving different individuals and jurisdictions, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 3,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news2_para",
        "news1",
        "other1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe unrelated events: an underground school in Kharkiv, a WGA strike in Hollywood, lab-grown meat approvals in the US, and the acquisition of First Republic Bank by JPMorgan. No factual contradictions exist between them.\"\n}"
    },
    {
      "id": 93,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other3",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe different events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 64,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "other3",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 refers to the 'Rivers and Harbors Appropriation Act of 1899,' while Doc 5 incorrectly refers to the 'Rivers and Ports Budget Act,' creating a factual contradiction about the specific law cited in the lawsuit.\"\n}"
    },
    {
      "id": 83,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other3",
        "other1",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train derailment in Pakistan, church collapse in Mexico, typhoon in China, and train collision in India) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 193,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states the repatriated items include the 'Lombok treasure', while Doc 3 states the repatriated items exclude the 'Lombok treasure', creating a factual contradiction about the same event.\"\n}"
    },
    {
      "id": 142,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_conflict",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        4,
        5
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe distinct events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    },
    {
      "id": 237,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other3",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"Doc 5 incorrectly states that Finland and Norway 'strongly supported the execution,' while Doc 2 correctly states they 'strongly condemned' it.\"\n}"
    },
    {
      "id": 207,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states the Luna-25 'continued to exist' after crashing, while Doc 5 states it 'ceased to exist' after the collision with the Moon's surface.\"\n}"
    },
    {
      "id": 108,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other2",
        "news1",
        "other3",
        "other1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe different events or provide consistent information about the same events without factual contradictions.\"\n}"
    },
    {
      "id": 210,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other3",
        "other1",
        "other2",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 190,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_conflict",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        4
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents; they describe separate events in different countries.\"\n}"
    },
    {
      "id": 178,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events or entities without factual contradictions.\"\n}"
    },
    {
      "id": 97,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news2_para",
        "other2",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (train crash in Italy, gas station explosion in Dagestan, wildfires in multiple regions, and warehouse explosion in Uzbekistan) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 73,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other2",
        "news2_conflict",
        "news1",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 4],\n  \"reason\": \"Doc 3 states that none of UNRWA's schools were damaged in Ain al-Hilweh, while Doc 4 claims two schools were damaged.\"\n}"
    },
    {
      "id": 92,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_conflict",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions exist between the documents as they describe unrelated events.\"\n}"
    },
    {
      "id": 105,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_conflict",
        "other3",
        "news1"
      ],
      "gold_exists": true,
      "gold_docs": [
        3,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        3,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [3, 5],\n  \"reason\": \"Doc 3 states Hilary will no longer be a hurricane when approaching Baja California, while Doc 5 states it will still be a hurricane.\"\n}"
    },
    {
      "id": 159,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other3",
        "other1",
        "other2",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that France will deploy 7,000 soldiers, while Doc 5 claims France will withdraw 7,000 soldiers.\"\n}"
    },
    {
      "id": 118,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (a Chinese fishing vessel capsizing, a US Marine Osprey crash, a fire in New Zealand, and Typhoon Saola in China) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 172,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe the same event with consistent details or are unrelated, with no explicit factual contradictions.\"\n}"
    },
    {
      "id": 105,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "other3",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"No factual contradictions were found between the documents.\"\n}"
    },
    {
      "id": 25,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news1",
        "news2_para"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 135,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "news1",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Iranian protests, Croatian fan violence, Ecuadorian gang transfer, and Brazilian election ruling) with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 234,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_conflict",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states Khader Adnan had already been tried at the time of his death, while Doc 4 states he had not yet been tried.\"\n}"
    },
    {
      "id": 42,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "other2",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        2,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [2, 5],\n  \"reason\": \"The name of the Magen David Adom paramedic is inconsistent between Doc 2 (Motty Dahan) and Doc 5 (Yossi Cohen).\"\n}"
    },
    {
      "id": 63,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other2",
        "other1",
        "other3",
        "news2_conflict"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        5
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        5
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 5],\n  \"reason\": \"Doc 1 states that AFP reported a Sweden-based Iraqi refugee stomped on the Quran during a protest, while Doc 5 claims AFP denied this report.\"\n}"
    },
    {
      "id": 273,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "other2",
        "news2_para",
        "news1",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (Afghanistan school poisoning, Sudan displacement, Russian espionage case, and Lviv missile attack) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 57,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other2",
        "news2_conflict",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 states North Korea condemned the US plans to deploy a nuclear missile submarine, while Doc 4 claims North Korea 'welcomed' the deployment, creating a factual contradiction about the same event.\"\n}"
    },
    {
      "id": 260,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "other1",
        "other2",
        "news2_para",
        "news1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": true,
      "pred_docs": [
        4,
        5
      ],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [4, 5],\n  \"reason\": \"Doc 4 and Doc 5 contradict each other regarding the outcome of the attack on the Russian ship 'Olenegorsky Gornyak'â€”Doc 4 states it was damaged and unable to conduct combat operations, while Doc 5 says it was 'visually detected and destroyed' by Russian forces.\"\n}"
    },
    {
      "id": 222,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other1",
        "news1",
        "news2_para",
        "other2",
        "other3"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"The documents describe distinct events in different countries and contexts, with no factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 180,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "news2_conflict",
        "other3",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        3
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        3
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 3],\n  \"reason\": \"Doc 1 states that police used water cannon against protesters, while Doc 3 claims police withheld water cannon, creating a factual contradiction about the same event.\"\n}"
    },
    {
      "id": 202,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "other3",
        "news1",
        "news2_conflict",
        "other2",
        "other1"
      ],
      "gold_exists": true,
      "gold_docs": [
        2,
        3
      ],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 0,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents describe distinct events (assassination attempt in Bulgaria, Israeli-Palestinian conflict, Egypt-Israel border incident, and Russian car bombing) and do not contain factual contradictions about the same event or entity.\"\n}"
    },
    {
      "id": 90,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "other1",
        "other3",
        "news2_conflict",
        "other2"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        4
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        4
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 4],\n  \"reason\": \"Doc 1 and Doc 4 describe the same event but contradict on the social media platform where the post was shared (X, previously known as Twitter vs. X, previously known as Instagram).\"\n}"
    },
    {
      "id": 233,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_para",
        "other2",
        "other3",
        "other1"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent information about the same event without factual contradictions.\"\n}"
    },
    {
      "id": 236,
      "mode": "conflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news1",
        "news2_conflict",
        "other1",
        "other2",
        "other3"
      ],
      "gold_exists": true,
      "gold_docs": [
        1,
        2
      ],
      "pred_exists": true,
      "pred_docs": [
        1,
        2
      ],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": true,\n  \"conflicting_docs\": [1, 2],\n  \"reason\": \"Doc 1 states that authorities reported 27 deaths from the mine fire, while Doc 2 claims authorities denied the 27 deaths, creating a factual contradiction about the official confirmation of casualties.\"\n}"
    },
    {
      "id": 75,
      "mode": "nonconflict",
      "model": "Qwen_Qwen3-32B",
      "experiment_mode": "baseline",
      "perm_order": [
        "news2_para",
        "other1",
        "other3",
        "news1",
        "other2"
      ],
      "gold_exists": false,
      "gold_docs": [],
      "pred_exists": false,
      "pred_docs": [],
      "full_correct": 1,
      "used_pairs": 0,
      "raw_output": "\n\n{\n  \"conflict_exists\": false,\n  \"conflicting_docs\": [],\n  \"reason\": \"All documents either describe unrelated events or provide consistent accounts of the same event without factual contradictions.\"\n}"
    }
  ]
}